{"pages":[{"title":"About ikarus-999","text":"Intro. HE11ow World!!안녕하세요 노래, 음악을 좋아하는개발자입니다 🕹공부하는게 즐거워서 개발을 시작하게 되었어요 💽I like studying 💻I Like Developing 🖥 Contacts 📫 EMAIL = next.forr@gmail.com","link":"/about/index.html"}],"posts":[{"title":"GAN프로젝트_try","text":"Style GAN toy 프로젝트StyleGAN의 특징 이미지를 Style의 조합으로 보고Generator의 각 Layer마다 Style 정보를 입히는 방식으로 이미지 합성이 때 각 Layer에서 추가되는 Style은 이미지의 Coarse Feature(포즈, 성별 등)부터Fine Detail(머리색, 피부톤 등)까지각기 다른 Level의 Visual 속성들을 조절 가능StyleGAN은 생각보다 안정적이고 높은 퀄리티의 이미지 생성 네트워크 구조(Module) GAN이란 어떤 것일까??? Instance Norm? Generator 구조 설명 왼쪽이 Traditional Network, 오른쪽이 이 논문에서 제안한 Style-gased Generator. 왼쪽 네트워크와 오른쪽에 Synthesis Network가 똑같은 구조를 갖고 있지만,이전 GAN에서는 Latent z를 바로 Input으로 넣어줬던 것과는 다르게,StyleGAN에서는 학습된 Constant, (w) 값을 입력으로 사용함. 새롭게 Mapping Network와 Noise가 추가됨.. W를 Feature에 매핑하는 경우W는 Z처럼 고정된 분포를 따르지 않음. Sampling density는 학습된 Piecewise Continuous Mapping f(z)(f는 Mapping Network 입니다)에 의해 정해짐. 따라서, Warping(틀어짐)이 많이 일어나지 않음.그렇기 때문에 Factors of variation은 더욱 Linear하고, Disentangled (얽히지 않음).이것이 바로 z를 곧바로 Feature에 매핑하는 것보다 w에 매핑하는 것의 장점입니다 기존의 Generator (a)는Input Latent Vector (z)가 직접 Convolution, Upsampling 등을 거쳐 이미지로 변환되는 구조. Style-based Generator (b) 의 경우,(z)가 Fully-connected Layer로 구성된 Mapping Network을 거쳐Intermediate Latent Vector (w) 먼저 변환. (w)는 Constant Tensor가 이미지로 변환되는 과정에서스타일을 입히는 역할을 수행. 다양한 스타일의 이미지를 생성. Style Transfer를 실시간으로 가능케하는 Adaptive Instance Norm Synthesis Network (합성 네트워크)z를 중간 latent space W에 매핑을 한 뒤에 이 w는 “A”를 거쳐서 style, y=(ys,yb)로 변형됨. 이때 A는 학습된 affine transform 임. 그리고 이 style들은AdaIN(adaptive instance normalization) opeartion을 control 함. AdaIN은 style transfer를 할 때 많이 쓰이는 방법으로, 임의의 style transfer를 실시간으로 가능하게 함.여기서 feature map xi는normalized 된 다음에, style로 변환된 두 y로 scaled, biased 됨. (style이 입혀짐)이 과정을 매 layer 마다 반복함. 그리고 이러한 방법은 scale-specific control 을 가능하게 함. To be continued…","link":"/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/"},{"title":"TF2","text":"Tensorflow 2.x 사용법Tensor 생성 tf.constant() : list, tuple, Array 를 Tensor로 바꿈 tensor = tf.constant(arr) tensor.dtype : 데이터 타입 확인 tf.cast(tensor, dtype=tf.uint8) : TF int8로 데이터타입 바꾸기 tensor.numpy() : numpy array로 바꾸기 Tensor에 랜덤한 숫자들 생성 numpy에서는 기본적인 normal distribution 생성np.random.randn(9) : 9개의 불연속적이며 일정한 분포 난수 생성 Distribution에 따른 난수 생성 tf.random.normal중심극한 이론에 의한 연속적인 모양 tf.random.uniform불연속적이며 일정한 분포","link":"/2020/11/22/TF2/"},{"title":"firstpost1","text":"HEXO 블로그 설치와 사용법새 글 쓰는 법1$ hexo new [레이아웃이름] &quot;새 포스트이름&quot; 레이아웃 디폴트(바로 발행) : post 바로 발행되지 않는 글 : draft 1$ hexo publish &quot;새 포스트이름&quot; 으로 draft에서 publish 합니다. publish는 잘 쓰지 않는다 파일명 에러나기 때문. 그냥냅다 MarkDown으로 쓰고 hexo g -d로 해버림","link":"/2020/10/24/firstpost1/"},{"title":"fpost2","text":"머신러닝과 딥러닝의 차이머신러닝 머신러닝은 정형 데이터 표 형태의 데이터 딥러닝은 비정형 데이터 그림, 사진, 오디오 형태의 자연 데이터 머신러닝 기초 준비물 충분한 용량(RAM 32GB++, SSD 512GB++, i7-10Gen++)의 데스크탑 권장! 가장 먼저 파이썬, 텐서플로우 를 설치합니다. 설치 버전 확인!! 매우 중요합니다! 파이썬 텐서플로우 넘파이 &amp; 싸이킷런 파이썬 버전을 여러개 설치 가능합니다. 이때는 환경 변수, IDE 경로 셋팅이 중요합니다. 윈도우라면 CMD보다는 powershell을 쓰는것이 편합니다. 제일 쉬운 방법은 아나콘다🛎… 하지만 용량이 큽니다. 써본 결과 리눅스에 도커가 최적 환경입니다⚙️. 추후 포스팅 예정 입니다.📯 Lets Burn the GPU!!🔥🔥🔥(TF2.0 wow!!)123456789101112131415161718192021import sysimport numpy as npimport tensorflow as tffrom datetime import datetime# tensorflow 실행모드를 확인합니다print(tf.executing_eagerly())shape = (int(10000), int(10000))startTime = datetime.now()with tf.device(&quot;/gpu&quot;): random_matrix = tf.random.uniform(shape=shape, minval=0, maxval=1) dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix)) sum_operation = tf.reduce_sum(dot_operation)result = sum_operationprint(result)print(&quot;\\n&quot; * 2)print(&quot;Time taken:&quot;, datetime.now() - startTime)print(&quot;\\n&quot; * 2)","link":"/2020/10/24/fpost2/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/10/24/hello-world/"},{"title":"fpost3","text":"일상을 끄적이다 - Mel Spectrogram 자동 분석을 위한 test page 입니다.M2U - March Of Fear비탄으로 가득 찬 이 도시 안에 떨어지는 Melody, 감정을 연기하는 춤추는 Endless rain… 거짓말로 얼룩진 관계들 속에 웃을 수 있는 거야? 세계를 노래하는 The March of Fear. We live in the tragedy! 유명한 비극과 같은 잔혹한 세계 속에 우리는 웃음짓고 있어. 이 세계를 비웃는 고결한 수호자들에게 지켜낼 것들은 두려웠던 자신뿐이니까! 숨을 멈춘 사람들 속에서 청명하게 울려퍼지는 Aria… 병든 마음으로 가득찬 이 세계에 폭격을 날려! 지금 웃고 있는 너도 Sociopath, 알잖아? 우리는 이 곳에 생명이 깃든 포성을 던져! 에픽세븐 OST 「Promise」깊은 절망 속에 갇혀 쓰러져 가는 나의 두 손을가만히 잡아 준 따스한 너의 온기를 아직난 기억해Now I can hear you눈을 감으면손 끝에서 널 느껴Now I can hear youI can find you이젠 알 수 있어 약속해 Promise I promise 잊지 않을게우리 함께 나눈 약속들을Promise I promise 어둠을 지난N 번째 하늘 아래 이곳에끝이 보이지 않아도 때론 지쳐서 주저 앉아도약속해 희망을 우리 마음에 간절히 모아빛을 향해Now I can hear you눈을 감으면손 끝에서 널 느껴Now I can hear youI can find you이젠 알 수 있어약속해 Promise I promise 잊지 않을게우리 함께 나눈 약속들을Promise I promise 어둠을 지난N 번째 하늘 아래 이곳에 다시 시작된 시간 다시 걸어가는 길함께하기에 나는 빛날 수 있어멀리 조금씩 보여 따뜻한 파란 빛이우리 마음을 여기에 모아 시작해 한번 더 약속해 Promise I promise 잊지 않을게우리 함께 나눈 약속들을Promise I promise 어둠을 지난N 번째 하늘 아래 약속들을 Promise I promise 어둠을 지난N 번째 하늘 아래 이곳에 Mel Spectrogram 분석 중인 음악입니다. GPU와 스토리지 지원좀 부탁드립니다.","link":"/2020/10/26/fpost3/"},{"title":"training_pc","text":"딥러닝 공부 후기 비정형 데이터를 다룰려면 GPU는 필수다. Why GPU ?? CPU보다 더 빠른 병렬 처리 가능 행렬곱 계산이 CPU보다 훨씬 빠름 계산 그래프 빌드, 처리 속도가 빠름. 비정형 데이터 처리엔 GPU가 필수 음성 딥러닝, 나도 해볼까?음성 딥러닝 음성 딥러닝은 결코 쉽지 않다. 딥러닝계의 보스급.신호처리 배워야 그나마 수월하다.초반 Feature Extraction 경험을 쌓는것을 권장한다.RNN계열의 LSTM으로 시작. 하지만,Attention, Transformer 날코딩 등 논문 구현 경험이 매우 중요하다.Mel Spectrogram을 한다 해도 원리를 잘 알아야 나중에 모델링과 데이터 분해가 쉽다. 딥러닝 입문 방법딥러닝 입문 하려면 수학은 필수. 정말 중요. 논문 구현 시도해보기1논문 구현 시도해보기2 어떤 논문에는 파라미터 하나도 없는 것도 있다.레이어 구조도만 있고 파라미터가 없는 것은 진짜 구현난이도 보스급. 딥러닝 자격증 취득 후기이것이 바로 딥러닝 자격증!! 문제 유형 Category 1: Basic model Category 2: Model from learning dataset Category 3: Image classificationConvolutional Neural Network with real-world image dataset Category 4: Natural language processing (NLP)NLP Text Classification with real-world text dataset Category 5: Time series, sequences and predictionsSequence Model with real-world numeric dataset 이 시험은 응시자가 TensorFlow 2.x를 통해 모델을 빌드하여 문제를 해결할 수 있는지테스트합니다. 머신러닝(ML) 및 딥러닝의 기본 원칙 TensorFlow 2.x에서 ML 모델 개발하기 심층신경망 및 합성곱 신경망(CNN)을 통한 이미지 인식, 객체 탐지, 텍스트 인식 알고리즘 빌드 컴퓨터가 정보를 ‘보는’ 방식과 플롯 손실 및 정확도 이해할 수 있도록 다른 크기 및 형태의 실제 이미지를 활용하여 합성곱에서 이미지의 경로를 시각화 과적합을 예방하기 위한 확장 및 드롭아웃과 같은 전략 탐색 TensorFlow를 이용하여 자연어 처리 문제를 해결하기 위해 신경망 적용 Google 공식 페이지 발췌 합격 점수 / 규칙 허용된 인터넷 브라우징은 Tensorflow document, 총 100점 만점에 90점 커트라인 난이도는 category 5가 가장 높음 시험 시간 : 5시간 (컴퓨터 딥러닝 훈련시간 포함) 따면 좋은 점 개발자 네트워크에 join 할 수가 있어요~ 자격증 네트워크 참고문서 그럼 20000~!","link":"/2020/11/16/training-pc/"},{"title":"딥러닝 입문과 준비","text":"딥러닝 시작해보기Tensor 이해하기 차원 0차원(상수) : Scalar값 1차원(리스트 씌운 상수), 2차원(2d), 3차원(3d), 4차원(4-d), n차원(n-d) : Tensor Numpy로 Tensor 표현과 응용이 가능 123456import numpy as nparr = np.array([[3, 6, 9], [2, 4, 8]])print(arr.dtype) # dtype('float64')print(arr.shape) # (2, 3)print(arr.size) # 2 * 3 = 6 차원 늘리기와 줄이기 reshape, -1 활용 123arr.reshape(-1) # 1차원으로 펼치기arr.reshape(-1, 3) # 첫번째 차원은 알아서, 두번째 차원은 shape 3 Ravel() : arr의 차원을 1로 바꿈(==&gt; Flatten) 123arr = np.array([[1, 2, 3], [4, 5, 6]]) # (2, 3)arr.ravel()arr.shape #(6, ) np.expand_dims() : 값을 유지하고 차원만 늘릴때 12arr = np.expand_dims(arr, -1) #(6, 1)arr.shape numpy array를 빠르게 채우는 방법! 12345678910111213# 0으로 채우기arr2 = np.zeros([3, 4]) # 3 * 4의 0이 채워진 배열one2 = np.ones([3, 4]) # 3 * 4의 1로 채워진 배열five2 = np.ones([3, 4]) * 5 # 1로 채운 값에 5를 다 곱함arr2 = np.arange(n, m) # n ~ m-1까지의 수로 배열 채우기# array([n ~ m-1])arr = np.arange(5, 11).reshape(2, -1)arr # array([5, 6, 7] # [8, 9, 10]) 모양이 맞지 않으면 Error… Index &amp; slicing 123456789101112131415# 리스트 인덱스 &amp; 슬라이싱nums = [2, 3, 4, 5, 6]nums[:-1] # 마지막 숫자 전까지 표시nums[::-1] # 리스트 안의 숫자를 거꾸로 표현nums = [[1, 2, 3], 4, 5, 6, 7]print(nums[0][1]) = 2 # 첫번째 리스트 안의 인덱스가 1인 숫자arr = np.array([5, 6, 7], [8, 9, 10])print(arr[1, 2]) # 10 --&gt; 인덱싱 [행, 열]print(arr[1:, 1:]) # [[9, 10]] Boolean Indexing1234data = np.random.randn(3, 3)print(data&lt;=0) # False, True로 나옴data[data &lt;=0] = 1 # 0 이하인 것을 1로 채우다","link":"/2020/11/22/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%84/"},{"title":"딥러닝 입문과 준비2","text":"딥러닝 시작해보기-2Broadcast두개의 행렬 shape가 서로 달라도한쪽의 차원이 같거나, 연산하는 값이 한 개일때shape에 맞게 복사해서 연산함 123456789101112131415161718192021arr = np.arange(6).reshape(-1, 3)# [[0, 1, 2], # [3, 4, 5]]arr + 3# [[3, 4, 5],# [6, 7, 8]]arr * 3# [[0, 3, 6],# [9, 12 15]arr + np.array([1, 2, 3])# [[1, 3, 5],# [4, 6, 8]]np.add(arr, 1)# 모든 원소에 1을 더함np.multiply(arr, 3)# 모든 원소에 3을 곱함 argmax, argmin 배열의 큰 값이나 작은 값의 index return 1234arr = np.array([1, 4, 6, 54, 3, 2])np.argmax(arr) # 54np.argmin(arr) # 1np.unique(arr) # 유일한 값 출력","link":"/2020/11/22/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%842/"}],"tags":[{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"DL","slug":"DL","link":"/tags/DL/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"Tensorflow2","slug":"Tensorflow2","link":"/tags/Tensorflow2/"},{"name":"TF2","slug":"TF2","link":"/tags/TF2/"},{"name":"HEXO","slug":"HEXO","link":"/tags/HEXO/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"Music EDA","slug":"Music-EDA","link":"/tags/Music-EDA/"},{"name":"Script","slug":"Script","link":"/tags/Script/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"GitPage","slug":"GitPage","link":"/categories/GitPage/"},{"name":"ilsang","slug":"ilsang","link":"/categories/ilsang/"},{"name":"Hexo","slug":"GitPage/Hexo","link":"/categories/GitPage/Hexo/"},{"name":"Music","slug":"ilsang/Music","link":"/categories/ilsang/Music/"}]}