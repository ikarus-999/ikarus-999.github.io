{"pages":[{"title":"About ikarus-999","text":"Intro. HE11ow World!!ì•ˆë…•í•˜ì„¸ìš” ë…¸ë˜, ìŒì•…, ì‘ê³¡ì„ ì¢‹ì•„í•˜ëŠ”ê°œë°œìì…ë‹ˆë‹¤ ğŸ•¹ê³µë¶€í•˜ëŠ”ê²Œ ì¦ê±°ì›Œì„œ ê°œë°œì„ ì‹œì‘í•˜ê²Œ ë˜ì—ˆì–´ìš” ğŸ’½I like studying ğŸ’»I Like Developing ğŸ–¥ Contacts ğŸ“« EMAIL = next.forr@gmail.com","link":"/about/index.html"}],"posts":[{"title":"Daconë„ì „ê¸°","text":"ë°ì´ì½˜ ë„ì „ í›„ê¸° í¥ë¯¸ë¡­ì§€ë§Œ ì‰½ì§€ëŠ” ì•Šë‹¤. ë§ ê·¸ëŒ€ë¡œ ìƒˆë¡œìš´ íŒŒìƒë³€ìˆ˜, ëª¨ë¸ì„ ë§ì´ ë§Œë“¤ë©´ ì ìˆ˜ê°€ ì˜¤ë¥´ê¸´ í•œë‹¤. ë°ì´ì½˜_ì—°ìŠµë¬¸ì œ ì—°ìŠµìš©ì´ê¸´ í•œë° BERTëª¨ë¸ í­ê²©ìœ¼ë¡œ ì–‘ë¯¼í•™ì‚´ ì´ ë²Œì¨ë¶€í„° ì‹œì‘ë˜ì—ˆâ€¦ã…ã„·ã„· ë²„íŠ¸ëª¨ë¸ ì•ˆì“°ê³ ë„ ìˆœìœ„ ì˜¬ë¦´ìˆ˜ëŠ” ìˆë‹¤. ì§€ê¸ˆë¶€í„° ê·¸ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤. ë°ì´ì½˜ ìˆœìœ„ë¥¼ ì˜¬ë¦´ìˆ˜ ìˆëŠ” ë°©ë²• - ì°½ì˜ì ì¸ modeling, K-cross Validation, parameter searching VDCNNì€ GPUê°€ ì˜ ë²„í…¨ì£¼ë©´ 0.86ê¹Œì§€ëŠ” ë§ˆêµ¬ë§ˆêµ¬ ì˜¬ë¦´ìˆ˜ ìˆìŒ. ì´ê²ƒì´ ë°”ë¡œ VDCNNì´ë‹¹! í•™ìŠµ ëª¨ë¸ì„ ê·¸ë¦¼ìœ¼ë¡œ ë³´ê¸° ì—¬ê¸°ì— ì—¬ëŸ¬ ê°€ì§€ ëª¨ë¸ Ensemble í•´ë³´ë©´ 0.88ì€ ê°€ëŠ¥í•´ë³´ì¼ ê²ƒ ê°™ë„¤ìš”. ì¶”ê°€ë¡œ ëª¨ë¸ Ensemble ì„ ì‹œë„ ì¶”ê°€ì ìœ¼ë¡œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ë§..(2020-12-09 ì¶”ê°€â€¦) Transformer","link":"/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/"},{"title":"GANí”„ë¡œì íŠ¸_try","text":"Style GAN toy í”„ë¡œì íŠ¸StyleGANì˜ íŠ¹ì§• ì´ë¯¸ì§€ë¥¼ Styleì˜ ì¡°í•©ìœ¼ë¡œ ë³´ê³ Generatorì˜ ê° Layerë§ˆë‹¤ Style ì •ë³´ë¥¼ ì…íˆëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ í•©ì„±ì´ ë•Œ ê° Layerì—ì„œ ì¶”ê°€ë˜ëŠ” Styleì€ ì´ë¯¸ì§€ì˜ Coarse Feature(í¬ì¦ˆ, ì„±ë³„ ë“±)ë¶€í„°Fine Detail(ë¨¸ë¦¬ìƒ‰, í”¼ë¶€í†¤ ë“±)ê¹Œì§€ê°ê¸° ë‹¤ë¥¸ Levelì˜ Visual ì†ì„±ë“¤ì„ ì¡°ì ˆ ê°€ëŠ¥StyleGANì€ ìƒê°ë³´ë‹¤ ì•ˆì •ì ì´ê³  ë†’ì€ í€„ë¦¬í‹°ì˜ ì´ë¯¸ì§€ ìƒì„± ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°(Module) GANì´ë€ ì–´ë–¤ ê²ƒì¼ê¹Œ??? Instance Norm? Generator êµ¬ì¡° ì„¤ëª… ì™¼ìª½ì´ Traditional Network, ì˜¤ë¥¸ìª½ì´ ì´ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ Style-gased Generator. ì™¼ìª½ ë„¤íŠ¸ì›Œí¬ì™€ ì˜¤ë¥¸ìª½ì— Synthesis Networkê°€ ë˜‘ê°™ì€ êµ¬ì¡°ë¥¼ ê°–ê³  ìˆì§€ë§Œ,ì´ì „ GANì—ì„œëŠ” Latent zë¥¼ ë°”ë¡œ Inputìœ¼ë¡œ ë„£ì–´ì¤¬ë˜ ê²ƒê³¼ëŠ” ë‹¤ë¥´ê²Œ,StyleGANì—ì„œëŠ” í•™ìŠµëœ Constant, (w) ê°’ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•¨. ìƒˆë¡­ê²Œ Mapping Networkì™€ Noiseê°€ ì¶”ê°€ë¨.. Wë¥¼ Featureì— ë§¤í•‘í•˜ëŠ” ê²½ìš°WëŠ” Zì²˜ëŸ¼ ê³ ì •ëœ ë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•ŠìŒ. Sampling densityëŠ” í•™ìŠµëœ Piecewise Continuous Mapping f(z)(fëŠ” Mapping Network ì…ë‹ˆë‹¤)ì— ì˜í•´ ì •í•´ì§. ë”°ë¼ì„œ, Warping(í‹€ì–´ì§)ì´ ë§ì´ ì¼ì–´ë‚˜ì§€ ì•ŠìŒ.ê·¸ë ‡ê¸° ë•Œë¬¸ì— Factors of variationì€ ë”ìš± Linearí•˜ê³ , Disentangled (ì–½íˆì§€ ì•ŠìŒ).ì´ê²ƒì´ ë°”ë¡œ zë¥¼ ê³§ë°”ë¡œ Featureì— ë§¤í•‘í•˜ëŠ” ê²ƒë³´ë‹¤ wì— ë§¤í•‘í•˜ëŠ” ê²ƒì˜ ì¥ì ì…ë‹ˆë‹¤ ê¸°ì¡´ì˜ Generator (a)ëŠ”Input Latent Vector (z)ê°€ ì§ì ‘ Convolution, Upsampling ë“±ì„ ê±°ì³ ì´ë¯¸ì§€ë¡œ ë³€í™˜ë˜ëŠ” êµ¬ì¡°. Style-based Generator (b) ì˜ ê²½ìš°,(z)ê°€ Fully-connected Layerë¡œ êµ¬ì„±ëœ Mapping Networkì„ ê±°ì³Intermediate Latent Vector (w) ë¨¼ì € ë³€í™˜. (w)ëŠ” Constant Tensorê°€ ì´ë¯¸ì§€ë¡œ ë³€í™˜ë˜ëŠ” ê³¼ì •ì—ì„œìŠ¤íƒ€ì¼ì„ ì…íˆëŠ” ì—­í• ì„ ìˆ˜í–‰. ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±. Style Transferë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ëŠ¥ì¼€í•˜ëŠ” Adaptive Instance Norm Synthesis Network (í•©ì„± ë„¤íŠ¸ì›Œí¬)zë¥¼ ì¤‘ê°„ latent space Wì— ë§¤í•‘ì„ í•œ ë’¤ì— ì´ wëŠ” â€œAâ€ë¥¼ ê±°ì³ì„œ style, y=(ys,yb)ë¡œ ë³€í˜•ë¨. ì´ë•Œ AëŠ” í•™ìŠµëœ affine transform ì„. ê·¸ë¦¬ê³  ì´ styleë“¤ì€AdaIN(adaptive instance normalization) opeartionì„ control í•¨. AdaINì€ style transferë¥¼ í•  ë•Œ ë§ì´ ì“°ì´ëŠ” ë°©ë²•ìœ¼ë¡œ, ì„ì˜ì˜ style transferë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°€ëŠ¥í•˜ê²Œ í•¨.ì—¬ê¸°ì„œ feature map xiëŠ”normalized ëœ ë‹¤ìŒì—, styleë¡œ ë³€í™˜ëœ ë‘ yë¡œ scaled, biased ë¨. (styleì´ ì…í˜€ì§)ì´ ê³¼ì •ì„ ë§¤ layer ë§ˆë‹¤ ë°˜ë³µí•¨. ê·¸ë¦¬ê³  ì´ëŸ¬í•œ ë°©ë²•ì€ scale-specific control ì„ ê°€ëŠ¥í•˜ê²Œ í•¨. To be continuedâ€¦","link":"/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/"},{"title":"firstpost1","text":"HEXO ë¸”ë¡œê·¸ ì„¤ì¹˜ì™€ ì‚¬ìš©ë²•ìƒˆ ê¸€ ì“°ëŠ” ë²•1$ hexo new [ë ˆì´ì•„ì›ƒì´ë¦„] &quot;ìƒˆ í¬ìŠ¤íŠ¸ì´ë¦„&quot; ë ˆì´ì•„ì›ƒ ë””í´íŠ¸(ë°”ë¡œ ë°œí–‰) : post ë°”ë¡œ ë°œí–‰ë˜ì§€ ì•ŠëŠ” ê¸€ : draft 1$ hexo publish &quot;ìƒˆ í¬ìŠ¤íŠ¸ì´ë¦„&quot; ìœ¼ë¡œ draftì—ì„œ publish í•©ë‹ˆë‹¤. publishëŠ” ì˜ ì“°ì§€ ì•ŠëŠ”ë‹¤ íŒŒì¼ëª… ì—ëŸ¬ë‚˜ê¸° ë•Œë¬¸. ê·¸ëƒ¥ëƒ…ë‹¤ MarkDownìœ¼ë¡œ ì“°ê³  hexo g -dë¡œ í•´ë²„ë¦¼","link":"/2020/10/24/firstpost1/"},{"title":"TF2","text":"Tensorflow 2.x ì‚¬ìš©ë²•Tensor ìƒì„± tf.constant() : list, tuple, Array ë¥¼ Tensorë¡œ ë°”ê¿ˆ tensor = tf.constant(arr) tensor.dtype : ë°ì´í„° íƒ€ì… í™•ì¸ tf.cast(tensor, dtype=tf.uint8) : TF int8ë¡œ ë°ì´í„°íƒ€ì… ë°”ê¾¸ê¸° tensor.numpy() : numpy arrayë¡œ ë°”ê¾¸ê¸° Tensorì— ëœë¤í•œ ìˆ«ìë“¤ ìƒì„± numpyì—ì„œëŠ” ê¸°ë³¸ì ì¸ normal distribution ìƒì„±np.random.randn(9) : 9ê°œì˜ ë¶ˆì—°ì†ì ì´ë©° ì¼ì •í•œ ë¶„í¬ ë‚œìˆ˜ ìƒì„± Distributionì— ë”°ë¥¸ ë‚œìˆ˜ ìƒì„± tf.random.normalì¤‘ì‹¬ê·¹í•œ ì´ë¡ ì— ì˜í•œ ì—°ì†ì ì¸ ëª¨ì–‘ tf.random.uniformë¶ˆì—°ì†ì ì´ë©° ì¼ì •í•œ ë¶„í¬","link":"/2020/11/22/TF2/"},{"title":"R ë„ì ì—¬ë³´ê¸°","text":"R ì‹œì‘í•´ë³´ê¸°R ë³€ìˆ˜ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137v1 &lt;-c(0, 1, 2, 3, NA) # ë²¡í„°v2 &lt;- 'a' # ë™ì  ë³€ìˆ˜ì— ë¬¸ì assignv2 = 'a' # ì •ì  ë³€ìˆ˜rm(v1, v2) # ë³€ìˆ˜ ì§€ìš°ê¸°v1 &lt;- c(0, 1, 2, 3)v2 &lt;- c(0, 1, 3, NA) # Errorv3 &lt;- c(0, 1, 3, NULL) # okmean(v1)mean(v2) # Errormean(v3) # okTRUE | TRUE # TRUETRUE | FALSE # TRUE!TRUE # ë’¤ì§‘ê¸° ì—°ì‚°!FALSE# ë²”ì£¼í˜• ë³€ìˆ˜key &lt;- factor('m', c('m', 'f'))nlevels(key)levels(key)[1] # 1ë ˆë²¨ ì¶”ì¶œlevels(key)[2] # ì¢…ë¥˜ ì¶”ì¶œlevels(key) &lt;- c('m', 'f')#vectorx &lt;- c(1,2,3,4,5)xy &lt;- c(1,2,3,4,&quot;a&quot;)ynames(x) &lt;- c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;)xx[1]x[2]x[-1]x[-2]x[1:3]x[3:5]x[&quot;a&quot;]names(x)[2]length(x)nrow(x)NROW(x)seq(1,10) # rangeseq(1:10)seq(1,10,1)seq(1,10,3)NROW(seq(1,10,3))rep(1:10, times=2) #ë°˜ë³µrep(1:10, each=2)rep(1:10, each=2, times=2)#listx &lt;- list(name=&quot;jo&quot;, he=&quot;999&quot;)xx$namex$hex[1]x[2]x[[1]] # ì¸ë±ì‹±x[[2]]y &lt;- list(name=&quot;k&quot;, he=c(1,2,3))yy[[1]]y[[2]]z &lt;- list(c(&quot;a&quot;,&quot;b&quot;), c(1,2,3,4))zz[[1]][2]z[[2]][-1]z[[2]][2:4]length(z[[1]])length(z[[2]])#matrixmatrix(c(1,2,3,4,5,6,7,8,9,10), nrow=2)matrix(c(1,2,3,4,5,6,7,8,9,10), nrow=5)m &lt;- matrix(1:9, nrow=3, dimnames=list(c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;),c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)))mrownames(m)colnames(m)m[1:2,]m[,1:2]m[1,1]m[3,3]m[-1,]m[,-2]m[-1,-2]m[-1,-3]m[m[,3]&gt;8,]#m[m[2:3]2]m[m[,3]&gt;=8,c(1,2)]m[c(2,3),c(1,2)]m[m[,3]&gt;=8,m[1,]&lt;5]mm[c(2,3),c(1,3)]#arrayarray(1:12, dim=c(3,4))x &lt;- array(1:12, dim=c(2,2,3))xx[,,2]m[1,]m1 &lt;- matrix(c(1,2,3,4,5,6,7,8,9), nrow=5)m1name &lt;- c(&quot;kim&quot;, &quot;lee&quot;, &quot;park&quot;)age &lt;- c(10,20,30)gender &lt;-factor(c(&quot;M&quot;,&quot;F&quot;,&quot;M&quot;))df &lt;- data.frame(name, age, gender)dfstr(df)df[df$age &gt;= 20 &amp; gender == &quot;F&quot;, c(&quot;name&quot;,&quot;age&quot;)]df[df$age &gt;= 20 &amp; gender == &quot;F&quot;, &quot;name&quot;]df[df[,2]&gt;=20 &amp; df[,3] == &quot;F&quot;, c(1,2)]","link":"/2020/11/29/R-%EB%81%84%EC%A0%81%EC%97%AC%EB%B3%B4%EA%B8%B0/"},{"title":"fpost2","text":"ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ë¨¸ì‹ ëŸ¬ë‹ ë¨¸ì‹ ëŸ¬ë‹ì€ ì •í˜• ë°ì´í„° í‘œ í˜•íƒœì˜ ë°ì´í„° ë”¥ëŸ¬ë‹ì€ ë¹„ì •í˜• ë°ì´í„° ê·¸ë¦¼, ì‚¬ì§„, ì˜¤ë””ì˜¤ í˜•íƒœì˜ ìì—° ë°ì´í„° ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆ ì¤€ë¹„ë¬¼ ì¶©ë¶„í•œ ìš©ëŸ‰(RAM 32GB++, SSD 512GB++, i7-10Gen++)ì˜ ë°ìŠ¤í¬íƒ‘ ê¶Œì¥! ê°€ì¥ ë¨¼ì € íŒŒì´ì¬, í…ì„œí”Œë¡œìš° ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. ì„¤ì¹˜ ë²„ì „ í™•ì¸!! ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤! íŒŒì´ì¬ í…ì„œí”Œë¡œìš° ë„˜íŒŒì´ &amp; ì‹¸ì´í‚·ëŸ° íŒŒì´ì¬ ë²„ì „ì„ ì—¬ëŸ¬ê°œ ì„¤ì¹˜ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ë•ŒëŠ” í™˜ê²½ ë³€ìˆ˜, IDE ê²½ë¡œ ì…‹íŒ…ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ìœˆë„ìš°ë¼ë©´ CMDë³´ë‹¤ëŠ” powershellì„ ì“°ëŠ”ê²ƒì´ í¸í•©ë‹ˆë‹¤. ì œì¼ ì‰¬ìš´ ë°©ë²•ì€ ì•„ë‚˜ì½˜ë‹¤ğŸ›â€¦ í•˜ì§€ë§Œ ìš©ëŸ‰ì´ í½ë‹ˆë‹¤. ì¨ë³¸ ê²°ê³¼ ë¦¬ëˆ…ìŠ¤ì— ë„ì»¤ê°€ ìµœì  í™˜ê²½ì…ë‹ˆë‹¤âš™ï¸. ì¶”í›„ í¬ìŠ¤íŒ… ì˜ˆì • ì…ë‹ˆë‹¤.ğŸ“¯ Lets Burn the GPU!!ğŸ”¥ğŸ”¥ğŸ”¥(TF2.0 wow!!)123456789101112131415161718192021import sysimport numpy as npimport tensorflow as tffrom datetime import datetime# tensorflow ì‹¤í–‰ëª¨ë“œë¥¼ í™•ì¸í•©ë‹ˆë‹¤print(tf.executing_eagerly())shape = (int(10000), int(10000))startTime = datetime.now()with tf.device(&quot;/gpu&quot;): random_matrix = tf.random.uniform(shape=shape, minval=0, maxval=1) dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix)) sum_operation = tf.reduce_sum(dot_operation)result = sum_operationprint(result)print(&quot;\\n&quot; * 2)print(&quot;Time taken:&quot;, datetime.now() - startTime)print(&quot;\\n&quot; * 2)","link":"/2020/10/24/fpost2/"},{"title":"Music Post","text":"ì¼ìƒì„ ë„ì ì´ë‹¤ - Mel Spectrogram ìë™ ë¶„ì„ì„ ìœ„í•œ test page ì…ë‹ˆë‹¤.M2U - March Of Fearë¹„íƒ„ìœ¼ë¡œ ê°€ë“ ì°¬ ì´ ë„ì‹œ ì•ˆì— ë–¨ì–´ì§€ëŠ” Melody, ê°ì •ì„ ì—°ê¸°í•˜ëŠ” ì¶¤ì¶”ëŠ” Endless rainâ€¦ ê±°ì§“ë§ë¡œ ì–¼ë£©ì§„ ê´€ê³„ë“¤ ì†ì— ì›ƒì„ ìˆ˜ ìˆëŠ” ê±°ì•¼? ì„¸ê³„ë¥¼ ë…¸ë˜í•˜ëŠ” The March of Fear. We live in the tragedy! ìœ ëª…í•œ ë¹„ê·¹ê³¼ ê°™ì€ ì”í˜¹í•œ ì„¸ê³„ ì†ì— ìš°ë¦¬ëŠ” ì›ƒìŒì§“ê³  ìˆì–´. ì´ ì„¸ê³„ë¥¼ ë¹„ì›ƒëŠ” ê³ ê²°í•œ ìˆ˜í˜¸ìë“¤ì—ê²Œ ì§€ì¼œë‚¼ ê²ƒë“¤ì€ ë‘ë ¤ì› ë˜ ìì‹ ë¿ì´ë‹ˆê¹Œ! ìˆ¨ì„ ë©ˆì¶˜ ì‚¬ëŒë“¤ ì†ì—ì„œ ì²­ëª…í•˜ê²Œ ìš¸ë ¤í¼ì§€ëŠ” Ariaâ€¦ ë³‘ë“  ë§ˆìŒìœ¼ë¡œ ê°€ë“ì°¬ ì´ ì„¸ê³„ì— í­ê²©ì„ ë‚ ë ¤! ì§€ê¸ˆ ì›ƒê³  ìˆëŠ” ë„ˆë„ Sociopath, ì•Œì–ì•„? ìš°ë¦¬ëŠ” ì´ ê³³ì— ìƒëª…ì´ ê¹ƒë“  í¬ì„±ì„ ë˜ì ¸! ì—í”½ì„¸ë¸ OST ã€ŒPromiseã€ê¹Šì€ ì ˆë§ ì†ì— ê°‡í˜€ ì“°ëŸ¬ì ¸ ê°€ëŠ” ë‚˜ì˜ ë‘ ì†ì„ê°€ë§Œíˆ ì¡ì•„ ì¤€ ë”°ìŠ¤í•œ ë„ˆì˜ ì˜¨ê¸°ë¥¼ ì•„ì§ë‚œ ê¸°ì–µí•´Now I can hear youëˆˆì„ ê°ìœ¼ë©´ì† ëì—ì„œ ë„ ëŠê»´Now I can hear youI can find youì´ì   ì•Œ ìˆ˜ ìˆì–´ ì•½ì†í•´ Promise I promise ìŠì§€ ì•Šì„ê²Œìš°ë¦¬ í•¨ê»˜ ë‚˜ëˆˆ ì•½ì†ë“¤ì„Promise I promise ì–´ë‘ ì„ ì§€ë‚œN ë²ˆì§¸ í•˜ëŠ˜ ì•„ë˜ ì´ê³³ì—ëì´ ë³´ì´ì§€ ì•Šì•„ë„ ë•Œë¡  ì§€ì³ì„œ ì£¼ì € ì•‰ì•„ë„ì•½ì†í•´ í¬ë§ì„ ìš°ë¦¬ ë§ˆìŒì— ê°„ì ˆíˆ ëª¨ì•„ë¹›ì„ í–¥í•´Now I can hear youëˆˆì„ ê°ìœ¼ë©´ì† ëì—ì„œ ë„ ëŠê»´Now I can hear youI can find youì´ì   ì•Œ ìˆ˜ ìˆì–´ì•½ì†í•´ Promise I promise ìŠì§€ ì•Šì„ê²Œìš°ë¦¬ í•¨ê»˜ ë‚˜ëˆˆ ì•½ì†ë“¤ì„Promise I promise ì–´ë‘ ì„ ì§€ë‚œN ë²ˆì§¸ í•˜ëŠ˜ ì•„ë˜ ì´ê³³ì— ë‹¤ì‹œ ì‹œì‘ëœ ì‹œê°„ ë‹¤ì‹œ ê±¸ì–´ê°€ëŠ” ê¸¸í•¨ê»˜í•˜ê¸°ì— ë‚˜ëŠ” ë¹›ë‚  ìˆ˜ ìˆì–´ë©€ë¦¬ ì¡°ê¸ˆì”© ë³´ì—¬ ë”°ëœ»í•œ íŒŒë€ ë¹›ì´ìš°ë¦¬ ë§ˆìŒì„ ì—¬ê¸°ì— ëª¨ì•„ ì‹œì‘í•´ í•œë²ˆ ë” ì•½ì†í•´ Promise I promise ìŠì§€ ì•Šì„ê²Œìš°ë¦¬ í•¨ê»˜ ë‚˜ëˆˆ ì•½ì†ë“¤ì„Promise I promise ì–´ë‘ ì„ ì§€ë‚œN ë²ˆì§¸ í•˜ëŠ˜ ì•„ë˜ ì•½ì†ë“¤ì„ Promise I promise ì–´ë‘ ì„ ì§€ë‚œN ë²ˆì§¸ í•˜ëŠ˜ ì•„ë˜ ì´ê³³ì— Mel Spectrogram ë¶„ì„ ì¤‘ì¸ ìŒì•…ì…ë‹ˆë‹¤. GPUì™€ ìŠ¤í† ë¦¬ì§€ ì§€ì›ì¢€ ë¶€íƒë“œë¦½ë‹ˆë‹¤.","link":"/2020/10/26/fpost3/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/10/24/hello-world/"},{"title":"ë”¥ëŸ¬ë‹ ì…ë¬¸ê³¼ ì¤€ë¹„2","text":"ë”¥ëŸ¬ë‹ ì‹œì‘í•´ë³´ê¸°-2Broadcastë‘ê°œì˜ í–‰ë ¬ shapeê°€ ì„œë¡œ ë‹¬ë¼ë„í•œìª½ì˜ ì°¨ì›ì´ ê°™ê±°ë‚˜, ì—°ì‚°í•˜ëŠ” ê°’ì´ í•œ ê°œì¼ë•Œshapeì— ë§ê²Œ ë³µì‚¬í•´ì„œ ì—°ì‚°í•¨ 123456789101112131415161718192021arr = np.arange(6).reshape(-1, 3)# [[0, 1, 2], # [3, 4, 5]]arr + 3# [[3, 4, 5],# [6, 7, 8]]arr * 3# [[0, 3, 6],# [9, 12 15]arr + np.array([1, 2, 3])# [[1, 3, 5],# [4, 6, 8]]np.add(arr, 1)# ëª¨ë“  ì›ì†Œì— 1ì„ ë”í•¨np.multiply(arr, 3)# ëª¨ë“  ì›ì†Œì— 3ì„ ê³±í•¨ argmax, argmin ë°°ì—´ì˜ í° ê°’ì´ë‚˜ ì‘ì€ ê°’ì˜ index return 1234arr = np.array([1, 4, 6, 54, 3, 2])np.argmax(arr) # 54np.argmin(arr) # 1np.unique(arr) # ìœ ì¼í•œ ê°’ ì¶œë ¥","link":"/2020/11/22/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%842/"},{"title":"training_pc","text":"ë”¥ëŸ¬ë‹ ê³µë¶€ í›„ê¸° ë¹„ì •í˜• ë°ì´í„°ë¥¼ ë‹¤ë£°ë ¤ë©´ GPUëŠ” í•„ìˆ˜ë‹¤. Why GPU ?? CPUë³´ë‹¤ ë” ë¹ ë¥¸ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥ í–‰ë ¬ê³± ê³„ì‚°ì´ CPUë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„ ê³„ì‚° ê·¸ë˜í”„ ë¹Œë“œ, ì²˜ë¦¬ ì†ë„ê°€ ë¹ ë¦„. ë¹„ì •í˜• ë°ì´í„° ì²˜ë¦¬ì—” GPUê°€ í•„ìˆ˜ ìŒì„± ë”¥ëŸ¬ë‹, ë‚˜ë„ í•´ë³¼ê¹Œ?ìŒì„± ë”¥ëŸ¬ë‹ ìŒì„± ë”¥ëŸ¬ë‹ì€ ê²°ì½” ì‰½ì§€ ì•Šë‹¤. ë”¥ëŸ¬ë‹ê³„ì˜ ë³´ìŠ¤ê¸‰.ì‹ í˜¸ì²˜ë¦¬ ë°°ì›Œì•¼ ê·¸ë‚˜ë§ˆ ìˆ˜ì›”í•˜ë‹¤.ì´ˆë°˜ Feature Extraction ê²½í—˜ì„ ìŒ“ëŠ”ê²ƒì„ ê¶Œì¥í•œë‹¤.RNNê³„ì—´ì˜ LSTMìœ¼ë¡œ ì‹œì‘. í•˜ì§€ë§Œ,Attention, Transformer ë‚ ì½”ë”© ë“± ë…¼ë¬¸ êµ¬í˜„ ê²½í—˜ì´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤.Mel Spectrogramì„ í•œë‹¤ í•´ë„ ì›ë¦¬ë¥¼ ì˜ ì•Œì•„ì•¼ ë‚˜ì¤‘ì— ëª¨ë¸ë§ê³¼ ë°ì´í„° ë¶„í•´ê°€ ì‰½ë‹¤. ë”¥ëŸ¬ë‹ ì…ë¬¸ ë°©ë²•ë”¥ëŸ¬ë‹ ì…ë¬¸ í•˜ë ¤ë©´ ìˆ˜í•™ì€ í•„ìˆ˜. ì •ë§ ì¤‘ìš”. ë…¼ë¬¸ êµ¬í˜„ ì‹œë„í•´ë³´ê¸°1ë…¼ë¬¸ êµ¬í˜„ ì‹œë„í•´ë³´ê¸°2 ì–´ë–¤ ë…¼ë¬¸ì—ëŠ” íŒŒë¼ë¯¸í„° í•˜ë‚˜ë„ ì—†ëŠ” ê²ƒë„ ìˆë‹¤.ë ˆì´ì–´ êµ¬ì¡°ë„ë§Œ ìˆê³  íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” ê²ƒì€ ì§„ì§œ êµ¬í˜„ë‚œì´ë„ ë³´ìŠ¤ê¸‰. ë”¥ëŸ¬ë‹ ìê²©ì¦ ì·¨ë“ í›„ê¸°ì´ê²ƒì´ ë°”ë¡œ ë”¥ëŸ¬ë‹ ìê²©ì¦!! ë¬¸ì œ ìœ í˜• Category 1: Basic model Category 2: Model from learning dataset Category 3: Image classificationConvolutional Neural Network with real-world image dataset Category 4: Natural language processing (NLP)NLP Text Classification with real-world text dataset Category 5: Time series, sequences and predictionsSequence Model with real-world numeric dataset ì´ ì‹œí—˜ì€ ì‘ì‹œìê°€ TensorFlow 2.xë¥¼ í†µí•´ ëª¨ë¸ì„ ë¹Œë“œí•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ”ì§€í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹(ML) ë° ë”¥ëŸ¬ë‹ì˜ ê¸°ë³¸ ì›ì¹™ TensorFlow 2.xì—ì„œ ML ëª¨ë¸ ê°œë°œí•˜ê¸° ì‹¬ì¸µì‹ ê²½ë§ ë° í•©ì„±ê³± ì‹ ê²½ë§(CNN)ì„ í†µí•œ ì´ë¯¸ì§€ ì¸ì‹, ê°ì²´ íƒì§€, í…ìŠ¤íŠ¸ ì¸ì‹ ì•Œê³ ë¦¬ì¦˜ ë¹Œë“œ ì»´í“¨í„°ê°€ ì •ë³´ë¥¼ â€˜ë³´ëŠ”â€™ ë°©ì‹ê³¼ í”Œë¡¯ ì†ì‹¤ ë° ì •í™•ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹¤ë¥¸ í¬ê¸° ë° í˜•íƒœì˜ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ í™œìš©í•˜ì—¬ í•©ì„±ê³±ì—ì„œ ì´ë¯¸ì§€ì˜ ê²½ë¡œë¥¼ ì‹œê°í™” ê³¼ì í•©ì„ ì˜ˆë°©í•˜ê¸° ìœ„í•œ í™•ì¥ ë° ë“œë¡­ì•„ì›ƒê³¼ ê°™ì€ ì „ëµ íƒìƒ‰ TensorFlowë¥¼ ì´ìš©í•˜ì—¬ ìì—°ì–´ ì²˜ë¦¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹ ê²½ë§ ì ìš© Google ê³µì‹ í˜ì´ì§€ ë°œì·Œ í•©ê²© ì ìˆ˜ / ê·œì¹™ í—ˆìš©ëœ ì¸í„°ë„· ë¸Œë¼ìš°ì§•ì€ Tensorflow document, ì´ 100ì  ë§Œì ì— 90ì  ì»¤íŠ¸ë¼ì¸ ë‚œì´ë„ëŠ” category 5ê°€ ê°€ì¥ ë†’ìŒ ì‹œí—˜ ì‹œê°„ : 5ì‹œê°„ (ì»´í“¨í„° ë”¥ëŸ¬ë‹ í›ˆë ¨ì‹œê°„ í¬í•¨) ë”°ë©´ ì¢‹ì€ ì  ê°œë°œì ë„¤íŠ¸ì›Œí¬ì— join í•  ìˆ˜ê°€ ìˆì–´ìš”~ ìê²©ì¦ ë„¤íŠ¸ì›Œí¬ ì°¸ê³ ë¬¸ì„œ ê·¸ëŸ¼ 20000~!","link":"/2020/11/16/training-pc/"},{"title":"ë”¥ëŸ¬ë‹ ì…ë¬¸ê³¼ ì¤€ë¹„","text":"ë”¥ëŸ¬ë‹ ì‹œì‘í•´ë³´ê¸°Tensor ì´í•´í•˜ê¸° ì°¨ì› 0ì°¨ì›(ìƒìˆ˜) : Scalarê°’ 1ì°¨ì›(ë¦¬ìŠ¤íŠ¸ ì”Œìš´ ìƒìˆ˜), 2ì°¨ì›(2d), 3ì°¨ì›(3d), 4ì°¨ì›(4-d), nì°¨ì›(n-d) : Tensor Numpyë¡œ Tensor í‘œí˜„ê³¼ ì‘ìš©ì´ ê°€ëŠ¥ 123456import numpy as nparr = np.array([[3, 6, 9], [2, 4, 8]])print(arr.dtype) # dtype('float64')print(arr.shape) # (2, 3)print(arr.size) # 2 * 3 = 6 ì°¨ì› ëŠ˜ë¦¬ê¸°ì™€ ì¤„ì´ê¸° reshape, -1 í™œìš© 123arr.reshape(-1) # 1ì°¨ì›ìœ¼ë¡œ í¼ì¹˜ê¸°arr.reshape(-1, 3) # ì²«ë²ˆì§¸ ì°¨ì›ì€ ì•Œì•„ì„œ, ë‘ë²ˆì§¸ ì°¨ì›ì€ shape 3 Ravel() : arrì˜ ì°¨ì›ì„ 1ë¡œ ë°”ê¿ˆ(==&gt; Flatten) 123arr = np.array([[1, 2, 3], [4, 5, 6]]) # (2, 3)arr.ravel()arr.shape #(6, ) np.expand_dims() : ê°’ì„ ìœ ì§€í•˜ê³  ì°¨ì›ë§Œ ëŠ˜ë¦´ë•Œ 12arr = np.expand_dims(arr, -1) #(6, 1)arr.shape numpy arrayë¥¼ ë¹ ë¥´ê²Œ ì±„ìš°ëŠ” ë°©ë²•! 1234567891011121314# 0ìœ¼ë¡œ ì±„ìš°ê¸°arr2 = np.zeros([3, 4]) # 3 * 4ì˜ 0ì´ ì±„ì›Œì§„ ë°°ì—´one2 = np.ones([3, 4]) # 3 * 4ì˜ 1ë¡œ ì±„ì›Œì§„ ë°°ì—´five2 = np.ones([3, 4]) * 5 # 1ë¡œ ì±„ìš´ ê°’ì— 5ë¥¼ ë‹¤ ê³±í•¨arr2 = np.arange(n, m) # n ~ m-1ê¹Œì§€ì˜ ìˆ˜ë¡œ ë°°ì—´ ì±„ìš°ê¸°# array([n ~ m-1])arr = np.arange(5, 11).reshape(2, -1) # 5 ~ 10 : 6ê°œì˜ ìˆ«ì, (2, 3)arr # array([5, 6, 7] # [8, 9, 10]) ëª¨ì–‘ì´ ë§ì§€ ì•Šìœ¼ë©´ Errorâ€¦5, 6, 7, 8, 9ëŠ” 5ê°œì˜ ìˆ«ì5 * 1 ë§Œ ê°€ëŠ¥í•œ. Index &amp; slicing 123456789101112131415# ë¦¬ìŠ¤íŠ¸ ì¸ë±ìŠ¤ &amp; ìŠ¬ë¼ì´ì‹±nums = [2, 3, 4, 5, 6]nums[:-1] # ë§ˆì§€ë§‰ ìˆ«ì ì „ê¹Œì§€ í‘œì‹œnums[::-1] # ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ìˆ«ìë¥¼ ê±°ê¾¸ë¡œ í‘œí˜„nums = [[1, 2, 3], 4, 5, 6, 7]print(nums[0][1]) = 2 # ì²«ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ì¸ë±ìŠ¤ê°€ 1ì¸ ìˆ«ìarr = np.array([5, 6, 7], [8, 9, 10])print(arr[1, 2]) # 10 --&gt; ì¸ë±ì‹± [í–‰, ì—´]print(arr[1:, 1:]) # [[9, 10]] Boolean Indexing1234data = np.random.randn(3, 3)print(data&lt;=0) # False, Trueë¡œ ë‚˜ì˜´data[data &lt;=0] = 1 # 0 ì´í•˜ì¸ ê²ƒì„ 1ë¡œ ì±„ìš°ë‹¤","link":"/2020/11/22/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%84/"},{"title":"ë”¥ëŸ¬ë‹-ì…ë¬¸ê³¼-ì¤€ë¹„3","text":"ë”¥ëŸ¬ë‹ ì‹œì‘í•´ë³´ê¸°-3ì°¨ì›ìˆ˜ ëŠ˜ë¦¬ê¸°, ì¤„ì´ê¸°(TF2.x)1234567x = tf.expand_dims(x, 1)x.shape # (x.shape, 1)x[..., tf.newaxis].shape # (x.shape, 1)np.squeeze(x[0]).shape # x.shape ì°¨ì› ì¤„ì´ê¸° TF2.x LayersConvolution filters : layerì—ì„œ ì¶œë ¥ë ë•Œ ëª‡ê°œì˜ filter kernel_size : filter(weight) ì˜ ì‚¬ì´ì¦ˆ strides : ëª‡ ê°œì˜ pixelë§Œí¼ skipí•˜ë©´ì„œ sliding window í•  ê²ƒì¸ì§€ padding : same, zero activation : í™œì„±í™” í•¨ìˆ˜(Linear functionì€ ì¸µì„ ìŒ“ëŠ” ì˜ë¯¸ê°€ ì—†ë‹¤) to be Continuedâ€¦","link":"/2020/11/23/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%843/"},{"title":"ë”¥ëŸ¬ë‹-ì…ë¬¸ê³¼-ì¤€ë¹„4","text":"ë”¥ëŸ¬ë‹ ì‹œì‘í•´ë³´ê¸°-4ì¸ê³µì‹ ê²½ë§ê³¼ ì†ì‹¤í•¨ìˆ˜ ì¸ê³µì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì¡° ë‡Œì˜ í•™ìŠµë°©ë²•ì„ ìˆ˜í•™ì ìœ¼ë¡œ ëª¨ë¸ë§í•œ ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ê¸°ë³¸ êµ¬ì¡° : y = Wx+b\\(x_i\\) : ì…ë ¥, \\(w_i\\): ê°€ì¤‘ì¹˜, b : bias, f: í™œì„±í™”í•¨ìˆ˜u : ê²°í•©(Net), z: ì¶œë ¥ ë‰´ëŸ°ì—ëŠ” ì„ í˜• ê²°í•©ê³¼ í™œì„±í™” í•¨ìˆ˜ ê¸°ëŠ¥ì´ ë“¤ì–´ìˆìŒ ì…ë ¥ì¸µ, ì€ë‹‰ì¸µ, ì¶œë ¥ì¸µìœ¼ë¡œ êµ¬ì„±ë¨ ê° ë…¸ë“œì˜ ë‰´ëŸ° ì¶œë ¥ì€ ì§ì ‘ ì „ë‹¬ë˜ëŠ” ì •ë³´ì—ë§Œ ì˜ì¡´í•  ë¿ ë‹¤ë¥¸ ë…¸ë“œì™€ëŠ” ë¬´ê´€ ê·¸ë˜ì„œ? ë³‘ë ¬ì²˜ë¦¬ê°€ ê°€ëŠ¥í•¨. ì†ì‹¤ í•¨ìˆ˜(Loss or Cost function) ì‹ ê²½ë§ì˜ ì¶œë ¥ê°’ê³¼ ì‹¤ì œ ê²°ê³¼ê°’ì˜ ì°¨ì´ë¥¼ ì •ì˜í•˜ëŠ” í•¨ìˆ˜ ì‹ ê²½ë§ í•™ìŠµëª©í‘œëŠ” ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™” í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì›€ì§ì—¬ì•¼ í•¨ SGD, Adam ë“±ì˜ í•™ìŠµ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì†ì‹¤ í•¨ìˆ˜ íšŒê·€(Regression)ì œê³± ì˜¤ì°¨(MSE) ì‚¬ìš©, ìµœê·¼ì—ëŠ” rmse, maeì˜ ì¥ì ì´ ìˆëŠ” Huber Loss ì‚¬ìš©í•˜ëŠ” ì¶”ì„¸ Huber Loss?MAE + MSE -&gt; for Time Series Data!! ë¶„ë¥˜(Classification)í™œì„±í™” í•¨ìˆ˜ : softmax, ì†ì‹¤í•¨ìˆ˜ : cross-entropy ì•Œê³ ë¦¬ì¦˜ê³¼ ì—­ì „íŒŒ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ê²½ì‚¬ í•˜ê°•ë²•: ê¸°ìš¸ê¸°ë¥¼ ì´ìš©í•˜ì—¬ ì†ì‹¤í•¨ìˆ˜ S(\\theta) ê°’ì„ ìµœì í™” gradient(ê¸°ìš¸ê¸°)ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì¼ì • í¬ê¸°ë§Œí¼ ì´ë™í•˜ëŠ” ê²ƒì„ ë°˜ë³µí•˜ì—¬ì†ì‹¤í•¨ìˆ˜ì˜ ê°’ì„ ìµœì†Œí™”í•˜ëŠ” \\thetaì˜ ê°’ì„ ì°¾ìŒ \\[\\theta = \\theta - \\eta \\nabla_\\theta S(\\theta)\\] ì´ ë–„ \\eta ëŠ” ë¯¸ë¦¬ ì •í•´ì§„ learning rate(step size) ì´ê³  ë³´í†µ 1e-3 ~ 1e-4 ì •ë„ë¥¼ ì‚¬ìš© ì—­ì „íŒŒ ê³„ì‚° ê·¸ë˜í”„ ë…¸ë“œëŠ” ì—°ì‚°ì„, ì—£ì§€ëŠ” ë°ì´í„°ì˜ íë¦„ë°©í–¥ sigmoid í•¨ìˆ˜ ì—­ì „íŒŒ í•©ì„±í•¨ìˆ˜ ë¯¸ë¶„ë²•(Chain Rule) í–‰ë ¬ì—°ì‚°ê³¼ ì—­ì „íŒŒ 1 ì´ì§„ë¶„ë¥˜ 2-layer NN ì—­ì „íŒŒ to be continuedâ€¦","link":"/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/"},{"title":"ë”¥ëŸ¬ë‹-ì…ë¬¸ê³¼-ì¤€ë¹„5","text":"ë”¥ëŸ¬ë‹ ì‹œì‘í•´ë³´ê¸°-5ì„ í˜•ëŒ€ìˆ˜ ë°°ì›Œë³´ê¸°(í–‰ë ¬ì„ ì•„ë¬´ë¦¬ ê³±í•˜ê³  ë”í•´ë„ ì„ ëª¨ì–‘)Scala : í¬ê¸°ë§Œ ì¡´ì¬í•˜ëŠ” ì–‘Vector : ì†ë„, ìœ„ì¹˜ì´ë™, í˜, ê³µê°„ë’¤í‹€ë¦¼ê³¼ ê°™ì´ í¬ê¸°ì™€ ë°©í–¥ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ì–‘ Norm ? nì°¨ì› ë²¡í„° $$\\vec{x} = (x_1, x_2, \\cdots x_n)$$Norm $$\\lVert x \\rVert = \\sqrt{x_1^1 + x_2^2 + \\cdots + x_n^2}$$ â€œì›ì  Oì—ì„œ ì \\(x_1, x_2, \\cdots, x_n\\) ê¹Œì§€ì˜ ê±°ë¦¬â€ ë‚´ì  ? Inner product, Dot productí–‰ë ¬ë¼ë¦¬ ê³±í•  ë•ŒëŠ” ì°¨ì›ì„ ì£¼ì˜í•œë‹¤. A(m, n) * B(n, m) ë§Œ ê°€ëŠ¥ Transpose: ì „ì¹˜í–‰ë ¬(í–‰ê³¼ ì—´ì„ ë’¤ë°”ê¿ˆ) A.T numpy ì—°ì‚°(Element-wise operation) np.dot(x, y) (aka ë‚´ì , dot-product)ì™€ x * y(element-wise)ëŠ” ì„œë¡œ ë‹¤ë¦„. numpy ë¹„êµ, ë…¼ë¦¬ì—°ì‚°(element-wise operation)numpy Reductions argmax() : ìµœëŒ€ê°’ìˆëŠ” ì¸ë±ìŠ¤ë¥¼ ë¦¬í„´, argmin() : ìµœì†Œê°’ì˜ ì¸ë±ìŠ¤ ë¦¬í„´ np.all, np.any? ALL : Arrayë‚´ ëª¨ë“  ê°’ì´ TRUEì¸ê°€? any : Arrayë‚´ ê°’ì´ í•˜ë‚˜ë¼ë„ TRUEì¸ê°€? np.mean, np.median, np.std ë“± í†µê³„í•¨ìˆ˜ ì‚¬ìš© ê°€ëŠ¥ë”¥ëŸ¬ë‹ì— ëŒ€í•œ í™˜ìƒ ë³µì¡í•œ ë¬¸ì œë„ ì¸µì„ ê¹Šê³  ë„“ê²Œ ìŒ“ìœ¼ë©´ í•´ê²°ëœë‹¤ â€“&gt; Gradient Vanhshing, Initialize fault ìœ¼í•˜í•˜í•°ã…‹ã…‹ã…‹ $$Sigmoid(z) = \\frac{1} {1 + e^{-z}}$$Sigmoid ë„í•¨ìˆ˜ì˜ ìµœëŒ€ê°’ì€ 1/4 â€¦ â€“&gt; ê·¸ë˜ì„œ Gradient Vanishing ë‚˜ëŠ”ê±°ì„ ã…‡ã…‡ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ì´ˆê¸°í™”ì˜ ì¤‘ìš”ì„±$$t = wx+b$$ ì—ì„œ wê°€ 100, bê°€ 50ì´ë¼ë©´ xê°€ 0.01ì´ë”ë¼ë„ tëŠ” 51ì´ ë¨ì—­ì „íŒŒë•Œ sigmoid í•¨ìˆ˜ í†µê³¼ì‹œí‚¤ë©´ $$\\sigmaâ€™ (51)$$ ë¦¬í„´ë¨í•˜ì§€ë§Œ tê°€ 5ë§Œ ë„˜ì–´ë„ $$\\sigma (t)$$ ëŠ” 0ì— ìˆ˜ë ´ â€“&gt; ì´ê²ƒì´ ë°”ë¡œ Gradient Vanishingâ€¦ ê·¸ë˜ì„œ ì…ë ¥ì¸µì˜ ê°€ì¤‘ì¹˜wë¥¼ ëª¨ë‘ 0ìœ¼ë¡œ ë¦¬ì…‹!Forward Propagationë•Œ ë‘ë²ˆì§¸ ì¸µ ë‰´ëŸ°ì— ëª¨ë‘ ê°™ì€ ê°’ì´ ì „ë‹¬ë¨Backward Propagationë•Œ ë‘ì§¸ ì¸µ ê°€ì¤‘ì¹˜ê°€ ëª¨ë‘ ë˜‘ê°™ì´ ì—…ë°ì´íŠ¸ ==&gt; ì‹ ê²½ë§ í‘œí˜„ë ¥ ì œí•œ BiasëŠ” 0ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ëŠ”ê²Œ ì¼ë°˜ì ìœ¼ë¡œ íš¨ìœ¨ì  ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” 2 í‘œì¤€ ì •ê·œë¶„í¬ë¥¼ ì´ìš©í•œ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”Sigmoidí•¨ìˆ˜ì˜ ì¶œë ¥ê°’ì´ ê·¹ë‹¨ì ìœ¼ë¡œ(0 or 1)ì— ì¹˜ìš°ì¹˜ëŠ” í˜„ìƒ â€“&gt; Gradient Vanishing í‘œì¤€í¸ì°¨ë¥¼ 0.01ë¡œ í•˜ëŠ” ì •ê·œë¶„í¬ë¡œ ì´ˆê¸°í™”ê°€ì¤‘ì¹˜ê°€ ëª¨ì—¬ ìˆìŒ =&gt; ê¸°ìš¸ê¸° ì†Œì‹¤ ë¬¸ì œ ì–´ëŠì •ë„ ì™„í™”ë¨ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” 3 Xavierì´ˆê¸°í™” ë°©ë²•(2010) 1w = np.random.randn(n_input, n_output) / (n_input) ** 0.5 Sigmoidì™€ ê°™ì€ Sì í•¨ìˆ˜ì˜ ê²½ìš° ì¶œë ¥ê°’ë“¤ì´ ì •ê·œë¶„í¬ í˜•íƒœì´ì–´ì•¼ ì•ˆì •ì  í•™ìŠµ ê°€ëŠ¥ Sigmoid functionê³¼ Xavier Initë°©ë²•ì„ ì‚¬ìš©í–ˆì„ ê²½ìš° ê·¸ë˜í”„ ReLU ê³„ì—´ í•¨ìˆ˜ì—ëŠ” ì ì ˆí•˜ì§€ ì•ŠìŒlayerë¥¼ ê±°ì³ê°ˆ ìˆ˜ë¡ 0ì— ìˆ˜ë ´(converge) ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” 4He ì´ˆê¸°í™” ë°©ë²•(2015) 1w = np.random.randn(n_input, n_output) / (n_input / 2) ** 0.5 RELU + He init â€“&gt; 10 layerë¥¼ ê±°ì³ë„ í‘œì¤€í¸ì°¨ê°€ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ Summary ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ëŠ” ë„ˆë¬´ë‚˜ ì¤‘ìš”í•¨ tanhì˜ ê²½ìš° Xavier Init ë°©ë²•ì´ íš¨ìœ¨ì  ReLUê³„ì—´ í•¨ìˆ˜ì—ëŠ” He Init ë°©ë²•ì´ íš¨ìœ¨ì  ìµœê·¼ì—” ëŒ€ë¶€ë¶„ He Initë¥¼ ì£¼ë¡œ ì‚¬ìš©","link":"/2020/11/25/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%845/"},{"title":"ë”¥ëŸ¬ë‹-ì…ë¬¸ê³¼-ì¤€ë¹„6","text":"ë”¥ëŸ¬ë‹ ì‹œì‘í•´ë³´ê¸°-6ğŸ’¥Remind!! ë”¥ëŸ¬ë‹ì— ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ  ì„ í˜• í•¨ìˆ˜ë¡œëŠ” XORê³¼ ê°™ì€ non-linearí•œ ë¬¸ì œëŠ” í•´ê²°ì´ ì•ˆë¨;; ê·¸ëŸ¬ë©´ Hidden Layerë¥¼ ëŠ˜ë¦¬ë©´ ë˜ì§€ ì•Šì„ê¹Œ? $$f(ax+by) = af(x) + bf(y)$$ ë¼ëŠ” íŠ¹ì§• ë•Œë¬¸ì— N-layer ê¹Šì´ë¥¼ ì•„ë¬´ë¦¬ ìŒ“ì•„ë„ 1-Layerë¡œ ë™ì‘í•¨. ìµœì í™”(Opt) ì•Œê³ ë¦¬ì¦˜ ê²½ì‚¬í•˜ê°•ë²•(GD)$$\\theta = \\theta - \\eta \\nabla_\\theta S(\\theta)$$ Networkì˜ parameter=$$\\theta $$ ë¡œ í• ë•Œ ì†ì‹¤í•¨ìˆ˜ $$J(\\theta)$$ì˜ ê°’ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ê¸°ìš¸ê¸°$$\\nabla J(\\theta)$$ë¥¼ ì´ìš©í•˜ëŠ” ë°©ë²•GDì—ì„œëŠ” Gradientì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì¼ì • í¬ê¸°(lr)ë§Œí¼ ì´ë™í•˜ëŠ” ê²ƒì„ ë°˜ë³µí•˜ì—¬ loss functionì˜ ê°’ì„ ìµœì†Œí™” í•˜ëŠ” $$\\theta$$ì˜ ê°’ì„ ì°¾ìŒ, lr $$\\eta$$ ëŠ” ë³´í†µ 1e-3 ~ 1e-4 ì‚¬ì´ì—ì„œ ì‚¬ìš©í•¨.ë„ˆë¬´ í¬ë©´ global minimumì„ ì§€ë‚˜ì¹˜ê³  ë„ˆë¬´ ì‘ìœ¼ë©´ Local Minimumì— ë¹ ì§. í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•(SGD)ì „ì²´ Training setì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ batch Gradient Descent, ê³„ì‚°ëŸ‰ì´ ë§ì•„ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´mini-batchì— ëŒ€í•´ì„œë§Œ ì†ì‹¤í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í™•ë¥ ì  GDë¥¼ ì‚¬ìš©í•¨.ê°™ì€ ì‹œê°„ì— ë” ë§ì€ stepë¥¼ ê°ˆ ìˆ˜ ìˆìŒ, ì—¬ëŸ¬ë²ˆ ë°˜ë³µí•  ê²½ìš° batchì˜ ê²°ê³¼ì™€ ë¹„ìŠ·í•¨ GD vs SGDGD : í™•ì‹¤í•œë° ë„ˆë¬´ ëŠë¦¼ | SGD : ì¡°ê¸ˆ í—¤ë©”ì§€ë§Œ ë¹ ë¦„ Momentum : í˜„ì¬ Gradientë¥¼ í†µí•´ ì´ë™í•˜ëŠ” ë°©í–¥ê³¼ ë³„ê°œë¡œ ê³¼ê±°ì˜ ì´ë™ë°©ì‹ì„ ê¸°ì–µí•˜ë©´ì„œ ì¼ì¢…ì˜ ê´€ì„±ì„ ì£¼ëŠ” ë°©ì‹ AdaGrad(Adaptive Gradient) ë§ì´ ë³€í™”í–ˆë˜ ë³€ìˆ˜ë“¤ì€ step sizeë¥¼ ì‘ê²Œ í•˜ëŠ” ê²ƒìì£¼ ë“±ì¥í•˜ê±°ë‚˜ ë³€í™”ë¥¼ ë§ì´ í•œ ë³€ìˆ˜ë“¤ì€ optimumì— ê°€ê¹Œì´ ìˆì„ í™•ë¥ ì´ ë†’ê¸° ë•Œë¬¸ì— ì‘ì€ í¬ê¸°ë¡œ ì´ë™í•˜ë©´ì„œ ë¯¸ì„¸ì¡°ì ˆ ì ê²Œ ë³€í™”í•œ ë³€ìˆ˜ë“¤ì€ ë§ì´ ì´ë™í•´ì•¼í•  í™•ë¥ ì´ ë†’ê¸° ë•Œë¬¸ì— ë¨¼ì € ë¹ ë¥´ê²Œ lossê°’ì„ ì¤„ì´ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë™í•˜ëŠ” ë°©ì‹í•™ìŠµì„ ê³„ì† ì§„í–‰í•˜ë©´ step sizeê°€ ë„ˆë¬´ ì¤„ì–´ë“œëŠ” ë‹¨ì ì´ ìˆìŒ. RMSPropí•©ì„ ì§€ìˆ˜í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ Adagradì˜ ë‹¨ì ì„ í•´ê²°Gê°€ ë¬´í•œì • ì»¤ì§€ì§€ëŠ” ì•Šìœ¼ë©´ì„œ ìµœê·¼ ë³€í™”ëŸ‰ì˜ ë³€ìˆ˜ê°„ ìƒëŒ€ì ì¸ í¬ê¸° ì°¨ì´ëŠ” ìœ ì§€í•  ìˆ˜ ìˆìŒ. AdamMomentum + RMSProp ì§€ê¸ˆê¹Œì§€ ê³„ì‚°í•´ì˜¨ ê¸°ìš¸ê¸°ì˜ ì§€ìˆ˜í‰ê· ì„ ì €ì¥ rmspropê³¼ ìœ ì‚¬í•˜ê²Œ Gradientì˜ ì œê³±ê°’ì˜ ì§€ìˆ˜í‰ê· ì„ ì €ì¥ Overfitting(ê³¼ì í•©) Training Setì˜ ì§€ì—½ì ì¸ íŠ¹ì„±ê¹Œì§€ ë°˜ì˜í•´ Variance Highë¡œ Trainingë˜ì–´ì„œ Training Setì„ ì•”ê¸°í•´ë²„ë¦¬ëŠ” í˜„ìƒ Test Setì„ ì˜ ì˜ˆì¸¡í•˜ì§€ ëª»í•¨ ì£¼ë¡œ í‘œí˜„ë ¥ì´ ë†’ì€ ëª¨ë¸, ì¦‰ íŒŒë¼ë¯¸í„°ê°€ ë§ì€ ëª¨ë¸ì— ë°œìƒ ì •ê·œí™”(Regularization) ì†ì‹¤í•¨ìˆ˜ì— ê°€ì¤‘ì¹˜ì˜ í¬ê¸°ë¥¼ í¬í•¨ ê°€ì¤‘ì¹˜ê°€ ì‘ì•„ì§€ë„ë¡ í•™ìŠµí•œë‹¤ëŠ” ê²ƒì€ Outlier(Noise)ì˜ ì˜í–¥ì„ ì ê²Œ ë°›ìŒ L2 ì •ê·œí™” Rigde Regression L1 ì •ê·œí™”Sparse Modelì— ì•Œë§ìŒ.. ì‘ì€ ê°€ì¤‘ì¹˜ë“¤ì´ ê±°ì˜ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ì—¬ ëª‡ê°œì˜ ì¤‘ìš”í•œ ê°€ì¤‘ì¹˜ë“¤ë§Œ ë‚¨ìŒ. Lasso Regression ë¯¸ë¶„ ë¶ˆê°€ëŠ¥í•œ ì ì´ ìˆê¸° ë•Œë¬¸ì— Gradient-Base Learningì—ëŠ” ì£¼ì˜.. DropOutê° ë ˆì´ì–´ì˜ ì¼ì • ë¹„ìœ¨ë¡œ ë‰´ëŸ°ì˜ ì¶œë ¥ ê°’ì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ ë‚˜ë¨¸ì§€ ë‰´ëŸ°ë“¤ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•ê³¼ì í•©ì„ íš¨ê³¼ì ìœ¼ë¡œ ì˜ˆë°© ê°€ëŠ¥(Network ë‚´ë¶€ì˜ Ensemble í•™ìŠµìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŒ) ì—­ì „íŒŒëŠ” ReLUì²˜ëŸ¼ ë™ì‘Forward Propagationë•Œ ì‹œê·¸ë„ì„ í†µê³¼ì‹œí‚¨ ë‰´ëŸ°ì€ Backwardë•Œë„ í†µê³¼ì‹œí‚´dropëœ ë‰´ëŸ°ì€ Backward Propagationë•Œë„ ì‹œê·¸ë„ ì°¨ë‹¨ ë°˜ë©´, TESTë•ŒëŠ” ëª¨ë“  ë‰´ëŸ°ì— ì‹ í˜¸ë¥¼ ì „ë‹¬í•¨ Batch Normalizationí•™ìŠµí•˜ëŠ” ì´ì „ ì¸µì˜ íŒŒë¼ë¯¸í„° ë³€í™”ë¡œ í˜„ì¬ì¸µì˜ ì…ë ¥ ë¶„í¬ê°€ ë°”ë€ŒëŠ” í˜„ìƒì„ ë‚´ë¶€ ê³µë¶„ì‚° ë³€í™”(Internal Covariate Shift)ì´ì „ ì¸µì˜ ì‘ì€ íŒŒë¼ë¯¸í„° ë³€í™”ê°€ ì¦í­ë˜ì–´ ë’· ë ˆì´ì–´ì— í° ì˜í–¥ì„ ë°›ìŒ.ê·¸ë˜ì„œâ€¦ BN(2015) Gradient Vanishing, Explodingì„ ë°©ì§€í•˜ëŠ” ëŒ€í‘œì ì¸ ë°©ë²• ì§ì ‘ì ì¸ ë°©ë²•ì„. Training ê³¼ì • ìì²´ë¥¼ ì•ˆì •í™”ì‹œì¼œ í•™ìŠµì†ë„ë¥¼ ê°€ì†í™” í‰ê· ê³¼ ë¶„ì‚°ì„ ì¡°ì ˆí•˜ëŠ” ê³¼ì •ì´ NN ì•ˆì— í¬í•¨ ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì´ í•µì‹¬ì  Trainingí• ë•Œê° Mini Batchë§ˆë‹¤ $$\\gamma$$ ì™€ $$\\beta$$ë¥¼ êµ¬í•˜ê³  ì €ì¥í•´ ë‘  Testí• ë•Œêµ¬í–ˆë˜ $$\\gamma$$ ì™€ $$\\beta$$ì˜ í‰ê· ì„ ì‚¬ìš© Data Augmentationì¼ì¢…ì˜ Regularizationì‘ì—…, ë°ì´í„°ê°€ ì ì„ ë•Œ ì‚¬ìš©í•˜ë©´ ë§¤ìš° íš¨ê³¼ì ì¦‰ ë°ì´í„° ë³€í˜•","link":"/2020/11/27/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%846/"},{"title":"ë”¥ëŸ¬ë‹-ì…ë¬¸ê³¼-ì¤€ë¹„7","text":"ë”¥ëŸ¬ë‹ ì‹œì‘í•´ë³´ê¸°-7í•©ì„±ê³±(Convolution) Convolution? ì •ì˜ í•©ì„±ê³± ì—°ì‚°ì€ ë‘ í•¨ìˆ˜ f, g ê°€ìš´ë° í•˜ë‚˜ì˜ í•¨ìˆ˜ë¥¼ ë°˜ì „(reverse), ì „ì´(shift)ì‹œí‚¨ ë‹¤ìŒ, ë‹¤ë¥¸ í•˜ë‚˜ì˜ í•¨ìˆ˜ì™€ ê³±í•œ ê²°ê³¼ë¥¼ ì ë¶„í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ì´ë¥¼ ìˆ˜í•™ ê¸°í˜¸ë¡œ í‘œì‹œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ë˜í•œ g í•¨ìˆ˜ ëŒ€ì‹ ì— f í•¨ìˆ˜ë¥¼ ë°˜ì „, ì „ì´ ì‹œí‚¤ëŠ” ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ í‘œì‹œí•  ìˆ˜ë„ ìˆë‹¤. ì´ ë‘ ì—°ì‚°ì€ í˜•íƒœëŠ” ë‹¤ë¥´ì§€ë§Œ ê°™ì€ ê²°ê³¼ê°’ì„ ê°–ëŠ”ë‹¤. ìœ„ì˜ ì ë¶„ì—ì„œ ì ë¶„ êµ¬ê°„ì€ í•¨ìˆ˜ fì™€ gê°€ ì •ì˜ëœ ë²”ìœ„ì— ë”°ë¼ì„œ ë‹¬ë¼ì§„ë‹¤. ë˜í•œ ë‘ í™•ë¥  ë³€ìˆ˜ Xì™€ Yê°€ ìˆì„ ë•Œ ê°ê°ì˜ í™•ë¥  ë°€ë„ í•¨ìˆ˜ë¥¼ fì™€ gë¼ê³  í•˜ë©´, X+Yì˜ í™•ë¥  ë°€ë„ í•¨ìˆ˜ëŠ” $$f * g$$ë¡œ í‘œì‹œí•  ìˆ˜ ìˆë‹¤. â€“ Wikipedia ë¬´ì—‡ì¸ì§€ ëª¨ë¥´ê² ì£ ? ì‰½ê²Œ ë§í•˜ìë©´ ê¸°ì¡´ MLPì—ì„œëŠ” ì´ë¯¸ì§€ê°€ ì‚´ì§ì´ë¼ë„ íšŒì „ì´ ë˜ê±°ë‚˜ ìœ„ì¹˜ ì´ë™ì´ ìˆë‹¤ë©´ ì‹ ê²½ë§ ìì²´ë¥¼ ë‹¤ì‹œ í•™ìŠµí•´ì•¼ í•˜ì§€ë§Œ CNNì€ ì´ë¯¸ì§€ì˜ ë³€í™”ê°€ ìˆì–´ë„ ì¬í•™ìŠµ ì—†ì–´ë„ ê°€ëŠ¥í•¨. ëª¨ë“  pixelì„ ë¹„êµí•  ê²Œ ì ˆëŒ€ ì•„ë‹˜. Feature ì¶”ì¶œì— ì¤‘ì ì„ ë‘ . $$C_in$$ x $$C_out$$ ë²ˆì˜ í•©ì„±ê³± ì—°ì‚° biasëŠ” í•˜ë‚˜ì˜ ë²¡í„° Filter(kernel)ì˜ í¬ê¸°ì— ë”°ë¼ ì˜ìƒì˜ í¬ê¸°ê°€ ì¤„ì–´ë“œëŠ” ë¬¸ì œì ì„ í•´ê²°í•˜ê¸° ìœ„í•´ paddingì„ ì“´ë‹¤. í¬ê¸°ê°€ (2N + 1)ì¸ ì»¤ë„ì— ìƒí•˜ì¢Œìš°ì— Nê°œ Zero paddingì„ í•´ì£¼ë©´ ëœë‹¤. Sliding Window ë°©ì‹ìœ¼ë¡œ ì»¤ë„ì´ ì´ë™ë˜ëŠ”ë° ê·¸ í¬ê¸°ë¥¼ ì¡°ì ˆí•˜ë ¤ë©´ Strideë¥¼ ì“´ë‹¤. ë„ˆë¬´ í¬ë©´ ì¶œë ¥ Feature Mapì´ ê³¼ë„í•˜ê²Œ ì¤„ì–´ë“œëŠ” ê²½ìš°ê°€ ë°œìƒí•œë‹¤. ë³´ë‹¤ íš¨ìœ¨ì ì¸ Conv ì—°ì‚°ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” 1x1 Convë¥¼ ë„£ëŠ”ë‹¤ ì—°ì‚°ëŸ‰, íŒŒë¼ë¯¸í„° ê°œìˆ˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ BottleNeck êµ¬ì¡°ë¥¼ í™œìš©í•œë‹¤. í•˜í•„ 1x1 ?? 3x3 filter í•œê°œì™€ 1x1 + 3x3 parameter ë¹„êµ ê·¸ë˜ë„ ëª¨ë¥´ê² ë‹¤ë©´?? 12345678910111213141516import numpy as npnp.random((3, 3)).shape == (np.random((3, 1)) * np.random((1, 3)).shape)&gt;&gt; True# keras# k - kernel_size(ex. 3, 5, 7...)# n_filter - number of filters/channels í•„í„° ê°¯ìˆ˜conv1_1 = Conv(n_filters, (1, k))(input_1)conv1_2 = Conv(n_filters, (k, 1))(conv1_1)# ì™œ ë³‘ëª©?conv2 = Conv2D(96, (1, 1), ...)(conv1) # ì¤„ì˜€ë‹¤ê°€(receptive FieldëŠ” ê·¸ëŒ€ë¡œ, Feature mapì„ ë¯¸ë¦¬ ì¤„ì„.)conv3 = Conv2D(96, (3, 3), ...)(conv2) conv4 = Conv2D(128, (1, 1), ...)(conv3) # ë‹¤ì‹œ ëŠ˜ë¦¼ í•­ë“±í–‰ë ¬ì„ ë– ì˜¬ë¦¬ë©´ ì´í•´ê°€ ê°ˆê²ƒì´ë‹¤. CNN ë§Œë“¤ì—ˆëŠ”ë° ë„ˆë¬´ ëŠë¦¬ë„¤? ì–´ë–»ê²Œ í•˜ë©´ ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆì„ê¹Œâ€¦ Conv filterë¥¼ ë” ë„“ê²Œ ì“´ë‹¤. â€“&gt; GPU ì—°ì‚°ì´ ì‰¬ì›Œì§„ë‹¤ 12345# ì´ë ‡ê²Œ ë˜ì–´ìˆëŠ” ê±¸conv = Conv2D(96, (3, 3), ...)(conv)conv = Conv2D(96, (3, 3), ...)(conv)# ì•„ë˜ì²˜ëŸ¼ ë°”ê¾¼ë‹¤.conv = Conv2D(128, (3, 3), ...)(conv) GPUëŠ” ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê¸° ë•Œë¬¸ì— í•„í„° ê°¯ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ ë”ìš± ë¹¨ë¼ì§„ë‹¤. ì‰½ê²Œ ë§í•˜ë©´ 96ê°œì”© ë‘ë²ˆë³´ë‹¤ 128ê°œì”© í•œë²ˆì´ ë” ë¹ ë¥´ë‹¤. ì„¤ëª…. 96 // 3 = 32 2- layerì„ 1- layerë¡œ ë°”ê¿€ë• 32 // 2 = 16 16^0.5 = 4 4 * 32 = 128 ë˜ ë‹¤ë¥¸ ë°©ë²•ê° ì±„ë„ì—ì„œ ë³„ë„ì˜ 2d convë¥¼ í•˜ëŠ” ë°©ë²•in_channels * channel_multipliter ì¤‘ê°„ì±„ë„ì€ ì—°ê²°ë˜ê³  1x1 convë¡œ out_channelsì— ë§¤í•‘ 1234# Kerasfrom keras.layers import SeparableConv2Dnet = SeparableConv2D(32, (3, 3))(net)# it's almost 1:1 similar to the simple Keras Conv2D layer ì¶œì²˜ :source1source2","link":"/2020/11/30/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%847/"},{"title":"ë”¥ëŸ¬ë‹-ì…ë¬¸í•˜ê¸°-8","text":"ì˜¤ë””ì˜¤ ë”¥ëŸ¬ë‹ í•´ë³´ê¸°Reference Digital Signal Processing Lecture https://github.com/spatialaudio/digital-signal-processing-lecture Python for Signal Processing (unipingco) https://github.com/unpingco/Python-for-Signal-Processing Audio for Deep Learning (ë‚¨ê¸°í˜„ë‹˜) https://tykimos.github.io/2019/07/04/ISS_2nd_Deep_Learning_Conference_All_Together/ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‘ì—…ì„ ìœ„í•œ ì—°ìŠµ (ë°•ìˆ˜ì² ë‹˜) https://github.com/scpark20/audio-preprocessing-practice Musical Applications of Machine Learning https://mac.kaist.ac.kr/~juhan/gct634/ Awesome audio study materials for Korean (ìµœê·¼ìš°ë‹˜) https://github.com/keunwoochoi/awesome-audio-study-materials-for-korean T Academy(ì¶œì²˜) https://tacademy.skplanet.com/live/player/onlineLectureDetail.action?seq=178 1. Digital Signal Processingì†Œë¦¬ signalë¥¼ ì–´ë– í•œ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ í‘œí˜„í•˜ë©°, ì†Œë¦¬ì™€ ê´€ë ¨ëœ taskë¥¼ í•´ê²°í•˜ëŠ”ë° ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì†Œë¦¬ëŠ” ì–´ë– í•œ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆì„ê¹Œìš”? Sound?ì†Œë¦¬ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì§„ë™ìœ¼ë¡œ ì¸í•œ ê³µê¸°ì˜ ì••ì¶•ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì••ì¶•ì´ ì–¼ë§ˆë‚˜ ë¬ëŠëƒì— ë”°ë¼ì„œ í‘œí˜„ë˜ê²ƒì´ ë°”ë¡œ Wave(íŒŒë™)ì¸ë°ìš”. íŒŒë™ì€ ì§„ë™í•˜ë©° ê³µê°„/ë§¤ì§ˆì„ ì „íŒŒí•´ ë‚˜ê°€ëŠ” í˜„ìƒì…ë‹ˆë‹¤. ì§ˆëŸ‰ì˜ ì´ë™ì€ ì—†ì§€ë§Œ ì—ë„ˆì§€/ìš´ë™ëŸ‰ì˜ ìš´ë°˜ì€ ì¡´ì¬í•©ë‹ˆë‹¤. Waveì—ì„œ ì €í¬ê°€ ì–»ì„ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” í¬ê²Œ 3ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. Phase(Degress of displacement) : ìœ„ìƒ Amplitude(Intensity) : ì§„í­ Frequency : ì£¼íŒŒìˆ˜ Samplingìƒ˜í”Œë§ì€ ë¬´ì—‡ì¼ê¹Œìš”?? ì•„ë‚ ë¡œê·¸ ì •ë³´ë¥¼ ì˜ê²Œ ìª¼ê°œì„œ discreteí•œ ë””ì§€í„¸ ì •ë³´ë¡œ í‘œí˜„í•´ì•¼í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë¬´í•œí•˜ê²Œ ìª¼ê°œì„œ ì €ì¥í• ìˆ˜ ì—†ìœ¼ë‹ˆ, ì–´ë–¤ ê¸°ì¤€ì„ ê°€ì§€ê³  ì•„ë‚ ë¡œê·¸ ì •ë³´ë¥¼ ìª¼ê°œì„œ ëŒ€í‘œê°’ì„ ì·¨í•˜ê²Œ ë©ë‹ˆë‹¤. Convert into a sqeuence of binary values via Sampling and Quantization 1.1. Time domainì‹œê°„ì„ ê¸°ì¤€ìœ¼ë¡œ ì•„ë‚ ë¡œê·¸ ì‹œê·¸ë„ì„ ìª¼ê°œê²Œ ë˜ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. Samplingì„ í†µí•˜ì—¬ ì»´í“¨í„°ëŠ” ì†Œë¦¬ sequenceë¥¼ binary valueë¡œ ë°›ì•„ë“œë¦¬ê²Œ ë©ë‹ˆë‹¤. Sampling rate : ì–¼ë§ˆë‚˜ ì˜ê²Œ ìª¼ê°¤ ê²ƒì¸ê°€?ì˜ê°œ ìª¼ê°¤ìˆ˜ë¡ ì›ë³¸ ë°ì´í„°ì™€ ê±°ì´ ê°€ê¹Œì›Œì§€ê¸° ë–„ë¬¸ì— ì¢‹ì§€ë§Œ Dataì˜ ì–‘ì´ ì¦ê°€í•˜ê²Œ ë©ë‹ˆë‹¤. ë§Œì•½ ë„ˆë¬´ í¬ê²Œ ìª¼ê°œê²Œ ëœë‹¤ë©´, ì›ë³¸ ë°ì´í„°ë¡œ reconstructí•˜ê¸° í˜ë“¤ì–´ ì§ˆ ê²ƒì…ë‹ˆë‹¤. Sampling theoremìƒ˜í”Œë§ ë ˆì´íŠ¸ê°€ ìµœëŒ€ frequencyì˜ 2ë°° ë³´ë‹¤ ì»¤ì ¸ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.$ f_{s} &gt; 2f_{m} $ ì—¬ê¸°ì„œ $f_{s}$ëŠ” sampling rate, ê·¸ë¦¬ê³  $f_{m}$ì€ maximum frequencyë¥¼ ë§í•©ë‹ˆë‹¤. Nyqusit frequency = $f_{s}/2$, sampling rateì˜ ì ˆë°˜ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Samplingì€ ì¸ê°„ì˜ ì²­ê° ì˜ì—­ì— ë§ê²Œ í˜•ì„±ì´ ë©ë‹ˆë‹¤. Audio CD : 44.1 kHz(44100 sample/second) Speech communication : 8 kHz(8000 sample/second) 12345# library loadimport soundfile as sfimport librosaimport numpy as npimport matplotlib.pyplot as plt 1filename = &quot;./wav/voice.wav&quot; 12345678# íŒŒì¼ ë¡œë“œ ë°©ë²• 1y, sr = sf.read(filename, dtype='int16')print(&quot;Sample Rate: &quot;, sr)print(&quot;DATA: &quot;, type(y), y.shape, len(y), y)dur = len(y) / srprint(&quot;dur : &quot;, dur) Sample Rate: 16000 DATA: &lt;class 'numpy.ndarray'&gt; (48944,) 48944 [ -9 1 -5 ... -20 -16 -24] dur : 3.059 1234567# íŒŒì¼ ë¡œë“œ ë°©ë²• 2y, sr = librosa.load(filename, mono=True, sr=16000)print(&quot;Sample Rate: &quot;, sr)print(&quot;DATA: &quot;, type(y), y.shape, y)dur = len(y) / srprint(&quot;dur : &quot;, dur) Sample Rate: 16000 DATA: &lt;class 'numpy.ndarray'&gt; (48944,) [-2.7465820e-04 3.0517578e-05 -1.5258789e-04 ... -6.1035156e-04 -4.8828125e-04 -7.3242188e-04] dur : 3.059 Resamplingìƒ˜í”Œë§ëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œê¸ˆ ë” ë†’ì€ sampling rate í˜¹ì€ ë” ë‚®ì€ sampling rateë¡œ ë‹¤ì‹œ ìƒ˜í”Œë§í• ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•ŒëŠ” ì¼ë°˜ì ìœ¼ë¡œ interpolation(ë³´ê°„)ì„ í• ë•ŒëŠ” low-pass filterë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.(Windowed sinc function) 12import IPython.display as ipdy_8k = librosa.resample(y, sr, 8000) 1ipd.Audio(y_8k, rate=8000) 1len(y_8k) 24472 12# durationlen(y_8k)/8000 3.059 12y_2k = librosa.resample(y, sr, 4000)ipd.Audio(y_2k, rate=2000) 1len(y_2k) 12236 Nomalization &amp; Quantizationì‹œê°„ì˜ ê¸°ì¤€ì´ ì•„ë‹Œ ì‹¤ì œ amplitudeì˜ real valued ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œê·¸ë„ì˜ ê°’ì„ ì¡°ì ˆí•©ë‹ˆë‹¤. Amplitudeë¥¼ ì´ì‚°ì ì¸ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ê³ , signal ë°ì´í„°ì˜ Amplitudeë¥¼ ë°˜ì˜¬ë¦¼í•˜ê²Œ ë©ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì´ì‚°ì ì¸ êµ¬ê°„ì€ ì–´ë–»ê²Œ ë‚˜ëˆŒìˆ˜ ìˆì„ê¹Œìš”?, bitì˜ ë¹„íŠ¸ì— ì˜í•´ì„œ ê²°ì •ë©ë‹ˆë‹¤. B bitì˜ Quantization : $-2^{B-1}$ ~ $2^{B-1}-1$ Audio CDì˜ Quantization (16 bits) : $-2^{15}$ ~ $2^{15}-1$ ìœ„ ê°’ë“¤ì€ ë³´í†µ -1.0 ~ 1.0 ì˜ì—­ìœ¼ë¡œ scalingë˜ê¸°ë„ í•©ë‹ˆë‹¤. 123# Normalizenormed_wav = y / max(np.abs(y))ipd.Audio(normed_wav, rate=sr) 12345678#quantization í•˜ë©´ ìŒì§ˆì€ ë–¨ì–´ì§€ì§€ë§Œ lightí•œ ìë£Œí˜•ì´ ëœë‹¤.Bit = 8max_value = 2 ** (Bit-1)quantized_8_wav = normed_wav * max_valuequantized_8_wav = np.round(quantized_8_wav).astype(int)quantized_8_wav = np.clip(quantized_8_wav, -max_value, max_value-1)ipd.Audio(quantized_8_wav, rate=sr) mu-law encodingì‚¬ëŒì˜ ê·€ëŠ” ì†Œë¦¬ì˜ amplitudeì— ëŒ€í•´ logì ìœ¼ë¡œ ë°˜ì‘í•©ë‹ˆë‹¤. ì¦‰, ì‘ì€ì†Œë¦¬ì˜ ì°¨ì´ëŠ” ì˜ì¡ì•„ë‚´ëŠ”ë° ë°˜í•´ ì†Œë¦¬ê°€ ì»¤ì§ˆìˆ˜ë¡ ê·¸ ì°¨ì´ë¥¼ ì˜ ëŠë¼ì§€ ëª»í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ íŠ¹ì„±ì„ waveê°’ì„ í‘œí˜„í•˜ëŠ”ë° ë°˜ì˜í•´ì„œ ì‘ì€ê°’ì—ëŠ” ë†’ì€ ë¶„ë³„ë ¥(high resolution)ì„, í°ê°’ë¼ë¦¬ëŠ” ë‚®ì€ ë¶„ë³„ë ¥(low resolution)ì„ ê°–ë„ë¡ í•©ë‹ˆë‹¤ 12def mu_law(x, mu=255): return np.sign(x) * np.log(1 + mu * np.abs(x)) / np.log(1 + mu) 1234567x = np.linspace(-1, 1, 1000)x_mu = mu_law(x)plt.figure(figsize=[6, 4])plt.plot(x)plt.plot(x_mu)plt.show() 12wav_mulaw = mu_law(normed_wav)ipd.Audio(wav_mulaw, rate=sr) to be continuedâ€¦ë’·ì¥ì—ì„œ ê³„ì†ë©ë‹ˆë‹¤.","link":"/2020/12/03/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%ED%95%98%EA%B8%B0-8/"},{"title":"ì¸ê³µì§€ëŠ¥ ê²½ì§„ëŒ€íšŒ í›„ê¸°","text":"ì¸ê³µì§€ëŠ¥ ë¬¸ì œí•´ê²° ê²½ì§„ëŒ€íšŒ ì°¸ê°€í›„ê¸° ğŸ”” ì •ë§ ì¹˜ì—´í–ˆë˜ ê²½ì§„ëŒ€íšŒì˜€ë‹¤. ì²˜ìŒì—ëŠ” ì´ë¯¸ì§€ ë©€í‹°ë¼ë²¨ ë‹¤ì¤‘ ë¶„ë¥˜ ë¬¸ì œê°€ ë‚˜ì™”ì—ˆê³  ê·¸ ì´í›„ ë³¸ì„ ëŒ€íšŒì—ì„œëŠ” NLP, OCR, GAN ë“± ì—¬ëŸ¬ ë„ë©”ì¸ ë¬¸ì œê°€ ì¶œí˜„í–ˆì—ˆë‹¤ ë² ì´ìŠ¤ë¼ì¸ ì½”ë“œ ê·¸ëŸ°ê±´ ì‚¬ì‹¤ìƒ ì—†ã…‹ìŒã…‹..ğŸ” ê·¸ëƒ¥ ë°ì´í„°ë¥¼ ë§ ê·¸ëŒ€ë¡œ í•´ì²´ ë¶„ì„ì„ í–ˆì–´ì•¼ í–ˆë‹¤. ì•„ë¬´ë¦¬ Data Clensingì„ í•´ë„ ê·¸ëŒ€ë¡œì¸ lossì™€ scoreâ€¦ 8:45ğŸ•› ê²°êµ­ ì•„ì˜ˆ ë¦¬ëª¨ë¸ë§, ë°ì´í„° Cleanize í•œ ë’¤ì— í•™ìŠµì„ ë‹¤ì‹œ ëŒë ¸ë‹¤. ì²œì‹ ë§Œê³  ëì—â€¦ ì°¸ê³ ë¡œ íŒ€ëª…ì€ í’ì„ ë„ìš°ê¸° ;; ìµœì¢… ëª…ë‹¨ì— ë°œí‘œë˜ê¸°ê¹Œì§€ ì—„ì²­ë‚œ ê¸´ì¥ê°ì´â€¦ğŸŒ¡ğŸ“ˆ","link":"/2020/12/09/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C-%ED%9B%84%EA%B8%B0/"},{"title":"ì°¸ê³ ë¦¬ìŠ¤íŠ¸","text":"í…ì„œí”Œë¡œìš° ê°œë°œì— ì°¸ê³ í•  ë§Œí•œ ë¬¸ì„œë“¤(References)Tensorflow Tutorial í…ì„œí”Œë¡œìš° íŠœí† ë¦¬ì–¼ ì‹œê³„ì—´ë°ì´í„° ìŠ¤í„°ë””ìë£Œ ëª¨ìŒ(Transformer) ì°¸ê³ ë…¼ë¬¸1 ë‘˜ëŸ¬ë³¼ë§Œí•œ ê¹ƒí—™ ë‘˜ëŸ¬ë³¼ë§Œí•œ ê¹ƒí—™2 ê¹ƒí—™ ë§í¬2 ìŒì„± ìì—°ì–´ì²˜ë¦¬ ìŠ¤í„°ë””ìë£Œ ëª¨ìŒ TacoTron Tensorflow ì˜¤ë””ì˜¤ ë”¥ëŸ¬ë‹ ì°¸ê³ ìë£Œ best VGGish kaggle Dataset ê³„ì† ì—…ë°ì´íŠ¸ ì˜ˆì • ì…ë‹ˆë‹¤.","link":"/2020/12/06/%EC%B0%B8%EA%B3%A0%EB%A6%AC%EC%8A%A4%ED%8A%B8/"},{"title":"kaggle_try","text":"ë‚¨ë“¤ì´ ì˜ ì•ˆí•˜ëŠ” ë°ì´í„°ì…‹ìœ¼ë¡œ ìºê¸€ ë„ì „ í›„ê¸° ë°ì´í„°ì…‹ ë§í¬ : https://www.kaggle.com/c/LANL-Earthquake-Prediction 12345678910111213141516from tqdm import tqdmimport pandas as pdimport numpy as npimport tensorflow as tfimport tensorflow.keras.backend as Kfrom tensorflow.keras import metricsfrom tensorflow.keras.layers import *from tensorflow.keras.models import *from tensorflow.keras.callbacks import *from tensorflow.keras.initializers import *import matplotlib.pyplot as pltimport seaborn as snsimport random, sys 1234pd.set_option('precision', 30)np.set_printoptions(precision = 30)np.random.seed(47) 12%%timetrain_df = pd.read_csv('./train.csv', dtype={'acoustic_data': np.int8, 'time_to_failure': np.float32}) CPU times: user 1min 30s, sys: 19.1 s, total: 1min 49s Wall time: 1min 49s 12X_train = train_df['acoustic_data'].valuesy_train = train_df['time_to_failure'].values Training dataì—ì„œ ì™„ì „í•œ ë°ì´í„° êµ¬ê°„ ì°¾ê¸°(0ì— ê·¼ì ‘í•œ failure time ì°¾ê¸°)12345678910ends_mask = np.less(y_train[:-1], y_train[1:])segment_ends = np.nonzero(ends_mask)train_segments = []start = 0for end in segment_ends[0]: train_segments.append((start, end)) start = end print(train_segments) [(0, 5656573), (5656573, 50085877), (50085877, 104677355), (104677355, 138772452), (138772452, 187641819), (187641819, 218652629), (218652629, 245829584), (245829584, 307838916), (307838916, 338276286), (338276286, 375377847), (375377847, 419368879), (419368879, 461811622), (461811622, 495800224), (495800224, 528777114), (528777114, 585568143), (585568143, 621985672)] 123fig, ax = plt.subplots()ax.set_title('segment size')ax.bar(np.arange(len(train_segments)), [ s[1] - s[0] for s in train_segments]) &lt;BarContainer object of 16 artists&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class EarthQuakeRandom(tf.keras.utils.Sequence): def __init__(self, x, y, x_mean, x_std, segments, ts_length, batch_size, steps_per_epoch): self.x = x self.y = y self.segments = segments self.ts_length = ts_length self.batch_size = batch_size self.steps_per_epoch = steps_per_epoch self.segments_size = np.array([s[1] - s[0] for s in segments]) self.segments_p = self.segments_size / self.segments_size.sum() self.x_mean = x_mean self.x_std = x_std def get_batch_size(self): return self.batch_size def get_ts_length(self): return self.ts_length def get_segments(self): return self.segments def get_segments_p(self): return self.segments_p def get_segments_size(self): return self.segments_size def __len__(self): return self.steps_per_epoch def __getitem__(self, idx): segment_index = np.random.choice(range(len(self.segments)), p=self.segments_p) segment = self.segments[segment_index] end_indexes = np.random.randint(segment[0] + self.ts_length, segment[1], size=self.batch_size) x_batch = np.empty((self.batch_size, self.ts_length)) y_batch = np.empty(self.batch_size, ) for i, end in enumerate(end_indexes): x_batch[i, :] = self.x[end - self.ts_length: end] y_batch[i] = self.y[end - 1] #x_batch = (x_batch - self.x_mean)/self.x_std return np.expand_dims(x_batch, axis=2), y_batch train / validation ë‚˜ëˆ„ê¸°(segments)12t_segments = [train_segments[i] for i in [ 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]]v_segments = [train_segments[i] for i in [ 0, 1, 2, 3]] training dataì— ëŒ€í•´ì„œë§Œ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚°12345678910111213141516x_sum = 0.count = 0for s in t_segments: x_sum += X_train[s[0]:s[1]].sum() count += (s[1] - s[0])X_train_mean = x_sum/countx2_sum = 0.for s in t_segments: x2_sum += np.power(X_train[s[0]:s[1]] - X_train_mean, 2).sum()X_train_std = np.sqrt(x2_sum/count)print(X_train_mean, X_train_std) 4.472289301190891 6.189013535612676 123456789101112131415161718192021train_gen = EarthQuakeRandom( x = X_train, y = y_train, x_mean = X_train_mean, x_std = X_train_std, segments = t_segments, ts_length = 150000, batch_size = 64, steps_per_epoch = 400)valid_gen = EarthQuakeRandom( x = X_train, y = y_train, x_mean = X_train_mean, x_std = X_train_std, segments = v_segments, ts_length = 150000, batch_size = 64, steps_per_epoch = 400) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158# https://www.kaggle.com/shujian/transformer-with-lstmtry: from dataloader import TokenList, pad_to_longest # for transformerexcept Exception as e: print(e)embed_size = 60class LayerNormalization(Layer): def __init__(self, eps=1e-6, **kwargs): self.eps = eps super(LayerNormalization, self).__init__(**kwargs) def build(self, input_shape): self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:], initializer=Ones(), trainable=True) self.beta = self.add_weight(name='beta', shape=input_shape[-1:], initializer=Zeros(), trainable=True) super(LayerNormalization, self).build(input_shape) def call(self, x): mean = K.mean(x, axis=-1, keepdims=True) std = K.std(x, axis=-1, keepdims=True) return self.gamma * (x - mean) / (std + self.eps) + self.beta def compute_output_shape(self, input_shape): return input_shapeclass ScaledDotProductAttention(): def __init__(self, d_model, attn_dropout=0.1): self.temper = np.sqrt(d_model) self.dropout = Dropout(attn_dropout) def __call__(self, q, k, v, mask): attn = Lambda(lambda x:K.batch_dot(x[0],x[1],axes=[2,2])/self.temper)([q, k]) if mask is not None: mmask = Lambda(lambda x:(-1e+10)*(1-x))(mask) attn = Add()([attn, mmask]) attn = Activation('softmax')(attn) attn = self.dropout(attn) output = Lambda(lambda x:K.batch_dot(x[0], x[1]))([attn, v]) return output, attnclass MultiHeadAttention(): # mode 0 - big martixes, faster; mode 1 - more clear implementation def __init__(self, n_head, d_model, d_k, d_v, dropout, mode=0, use_norm=True): self.mode = mode self.n_head = n_head self.d_k = d_k self.d_v = d_v self.dropout = dropout if mode == 0: self.qs_layer = Dense(n_head*d_k, use_bias=False) self.ks_layer = Dense(n_head*d_k, use_bias=False) self.vs_layer = Dense(n_head*d_v, use_bias=False) elif mode == 1: self.qs_layers = [] self.ks_layers = [] self.vs_layers = [] for _ in range(n_head): self.qs_layers.append(TimeDistributed(Dense(d_k, use_bias=False))) self.ks_layers.append(TimeDistributed(Dense(d_k, use_bias=False))) self.vs_layers.append(TimeDistributed(Dense(d_v, use_bias=False))) self.attention = ScaledDotProductAttention(d_model) self.layer_norm = LayerNormalization() if use_norm else None self.w_o = TimeDistributed(Dense(d_model)) def __call__(self, q, k, v, mask=None): d_k, d_v = self.d_k, self.d_v n_head = self.n_head if self.mode == 0: qs = self.qs_layer(q) # [batch_size, len_q, n_head*d_k] ks = self.ks_layer(k) vs = self.vs_layer(v) def reshape1(x): s = tf.shape(x) # [batch_size, len_q, n_head * d_k] x = tf.reshape(x, [s[0], s[1], n_head, d_k]) x = tf.transpose(x, [2, 0, 1, 3]) x = tf.reshape(x, [-1, s[1], d_k]) # [n_head * batch_size, len_q, d_k] return x qs = Lambda(reshape1)(qs) ks = Lambda(reshape1)(ks) vs = Lambda(reshape1)(vs) if mask is not None: mask = Lambda(lambda x:K.repeat_elements(x, n_head, 0))(mask) head, attn = self.attention(qs, ks, vs, mask=mask) def reshape2(x): s = tf.shape(x) # [n_head * batch_size, len_v, d_v] x = tf.reshape(x, [n_head, -1, s[1], s[2]]) x = tf.transpose(x, [1, 2, 0, 3]) x = tf.reshape(x, [-1, s[1], n_head*d_v]) # [batch_size, len_v, n_head * d_v] return x head = Lambda(reshape2)(head) elif self.mode == 1: heads = []; attns = [] for i in range(n_head): qs = self.qs_layers[i](q) ks = self.ks_layers[i](k) vs = self.vs_layers[i](v) head, attn = self.attention(qs, ks, vs, mask) heads.append(head); attns.append(attn) head = Concatenate()(heads) if n_head &gt; 1 else heads[0] attn = Concatenate()(attns) if n_head &gt; 1 else attns[0] outputs = self.w_o(head) outputs = Dropout(self.dropout)(outputs) if not self.layer_norm: return outputs, attn # outputs = Add()([outputs, q]) # sl: fix return self.layer_norm(outputs), attnclass PositionwiseFeedForward(): def __init__(self, d_hid, d_inner_hid, dropout=0.1): self.w_1 = Conv1D(d_inner_hid, 1, activation='relu') self.w_2 = Conv1D(d_hid, 1) self.layer_norm = LayerNormalization() self.dropout = Dropout(dropout) def __call__(self, x): output = self.w_1(x) output = self.w_2(output) output = self.dropout(output) output = Add()([output, x]) return self.layer_norm(output)class EncoderLayer(): def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1): self.self_att_layer = MultiHeadAttention(n_head, d_model, d_k, d_v, dropout=dropout) self.pos_ffn_layer = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout) def __call__(self, enc_input, mask=None): output, slf_attn = self.self_att_layer(enc_input, enc_input, enc_input, mask=mask) output = self.pos_ffn_layer(output) return output, slf_attndef GetPosEncodingMatrix(max_len, d_emb): pos_enc = np.array([ [pos / np.power(10000, 2 * (j // 2) / d_emb) for j in range(d_emb)] if pos != 0 else np.zeros(d_emb) for pos in range(max_len) ]) pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2]) # dim 2i pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2]) # dim 2i+1 return pos_encdef GetPadMask(q, k): ones = K.expand_dims(K.ones_like(q, 'float32'), -1) mask = K.cast(K.expand_dims(K.not_equal(k, 0), 1), 'float32') mask = K.batch_dot(ones, mask, axes=[2,1]) return maskdef GetSubMask(s): len_s = tf.shape(s)[1] bs = tf.shape(s)[:1] mask = K.cumsum(tf.eye(len_s, batch_shape=bs), 1) return mask No module named 'dataloader' 123456789101112131415161718192021222324252627282930313233def CnnTransformerModel(): i = Input(shape = (150000, 1)) x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(i) x = Convolution1D( 8, kernel_size = 10, strides = 10, activation='relu')(x) x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(x) x = Convolution1D(16, kernel_size = 10, strides = 10, activation='relu')(x) x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(x) x = Convolution1D(32, kernel_size = 10, strides = 10, activation='relu')(x) x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)(x) x = Convolution1D(64, kernel_size = 10, strides = 10, activation='relu')(x) x = Bidirectional(LSTM(128, return_sequences = True, return_state = False))(x) x = Bidirectional(LSTM(64, return_sequences = True, return_state = False))(x) x, slf_attn = MultiHeadAttention(n_head=5, d_model=300, d_k=64, d_v=64, dropout=0.3)(x, x, x) avg_pool = GlobalAveragePooling1D()(x) avg_pool = Dense(60,activation = 'relu')(avg_pool) y = Dense(1,activation = 'relu')(avg_pool) return Model(inputs = [i], outputs = [y]) 123model = CnnTransformerModel()model.compile(loss='mean_squared_error', optimizer='adam',metrics = ['mean_absolute_error'])model.summary() Model: &quot;model&quot; __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) [(None, 150000, 1)] 0 __________________________________________________________________________________________________ batch_normalization (BatchNorma (None, 150000, 1) 4 input_1[0][0] __________________________________________________________________________________________________ conv1d (Conv1D) (None, 15000, 8) 88 batch_normalization[0][0] __________________________________________________________________________________________________ batch_normalization_1 (BatchNor (None, 15000, 8) 32 conv1d[0][0] __________________________________________________________________________________________________ conv1d_1 (Conv1D) (None, 1500, 16) 1296 batch_normalization_1[0][0] __________________________________________________________________________________________________ batch_normalization_2 (BatchNor (None, 1500, 16) 64 conv1d_1[0][0] __________________________________________________________________________________________________ conv1d_2 (Conv1D) (None, 150, 32) 5152 batch_normalization_2[0][0] __________________________________________________________________________________________________ batch_normalization_3 (BatchNor (None, 150, 32) 128 conv1d_2[0][0] __________________________________________________________________________________________________ conv1d_3 (Conv1D) (None, 15, 64) 20544 batch_normalization_3[0][0] __________________________________________________________________________________________________ bidirectional (Bidirectional) (None, 15, 256) 197632 conv1d_3[0][0] __________________________________________________________________________________________________ bidirectional_1 (Bidirectional) (None, 15, 128) 164352 bidirectional[0][0] __________________________________________________________________________________________________ dense (Dense) (None, 15, 320) 40960 bidirectional_1[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 15, 320) 40960 bidirectional_1[0][0] __________________________________________________________________________________________________ lambda (Lambda) (None, None, 64) 0 dense[0][0] __________________________________________________________________________________________________ lambda_1 (Lambda) (None, None, 64) 0 dense_1[0][0] __________________________________________________________________________________________________ lambda_3 (Lambda) (None, None, None) 0 lambda[0][0] lambda_1[0][0] __________________________________________________________________________________________________ activation (Activation) (None, None, None) 0 lambda_3[0][0] __________________________________________________________________________________________________ dense_2 (Dense) (None, 15, 320) 40960 bidirectional_1[0][0] __________________________________________________________________________________________________ dropout (Dropout) (None, None, None) 0 activation[0][0] __________________________________________________________________________________________________ lambda_2 (Lambda) (None, None, 64) 0 dense_2[0][0] __________________________________________________________________________________________________ lambda_4 (Lambda) (None, None, 64) 0 dropout[0][0] lambda_2[0][0] __________________________________________________________________________________________________ lambda_5 (Lambda) (None, None, 320) 0 lambda_4[0][0] __________________________________________________________________________________________________ time_distributed (TimeDistribut (None, None, 300) 96300 lambda_5[0][0] __________________________________________________________________________________________________ dropout_1 (Dropout) (None, None, 300) 0 time_distributed[0][0] __________________________________________________________________________________________________ layer_normalization (LayerNorma (None, None, 300) 600 dropout_1[0][0] __________________________________________________________________________________________________ global_average_pooling1d (Globa (None, 300) 0 layer_normalization[0][0] __________________________________________________________________________________________________ dense_4 (Dense) (None, 60) 18060 global_average_pooling1d[0][0] __________________________________________________________________________________________________ dense_5 (Dense) (None, 1) 61 dense_4[0][0] ================================================================================================== Total params: 627,193 Trainable params: 627,079 Non-trainable params: 114 __________________________________________________________________________________________________ 123# from IPython.display import SVG# from keras.utils.vis_utils import model_to_dot# SVG(model_to_dot(model,show_shapes = True).create(prog='dot', format='svg')) 12345678import timestart_time = time.time()hist = model.fit( train_gen, epochs = 25, verbose = 1,validation_data= valid_gen)print(&quot;--- %s seconds ---&quot; % (time.time() - start_time)) Epoch 1/25 400/400 [==============================] - 92s 230ms/step - loss: 8.1259 - mean_absolute_error: 2.1690 - val_loss: 8.6962 - val_mean_absolute_error: 2.2990 Epoch 2/25 400/400 [==============================] - 93s 232ms/step - loss: 6.8734 - mean_absolute_error: 1.9745 - val_loss: 10.5941 - val_mean_absolute_error: 2.5199 Epoch 3/25 400/400 [==============================] - 92s 231ms/step - loss: 6.2273 - mean_absolute_error: 1.8582 - val_loss: 8.3263 - val_mean_absolute_error: 2.1892 Epoch 4/25 400/400 [==============================] - 93s 232ms/step - loss: 6.3129 - mean_absolute_error: 1.8750 - val_loss: 7.2582 - val_mean_absolute_error: 2.1842 Epoch 5/25 400/400 [==============================] - 93s 232ms/step - loss: 6.1699 - mean_absolute_error: 1.8555 - val_loss: 10.6914 - val_mean_absolute_error: 2.5315 Epoch 6/25 400/400 [==============================] - 93s 232ms/step - loss: 6.3945 - mean_absolute_error: 1.8601 - val_loss: 17.6278 - val_mean_absolute_error: 3.4488 Epoch 7/25 400/400 [==============================] - 91s 228ms/step - loss: 5.9358 - mean_absolute_error: 1.7905 - val_loss: 7.1590 - val_mean_absolute_error: 2.0332 Epoch 8/25 400/400 [==============================] - 91s 227ms/step - loss: 5.8317 - mean_absolute_error: 1.7861 - val_loss: 7.4188 - val_mean_absolute_error: 2.0401 Epoch 9/25 400/400 [==============================] - 90s 226ms/step - loss: 6.0664 - mean_absolute_error: 1.8154 - val_loss: 11.4744 - val_mean_absolute_error: 2.6900 Epoch 10/25 400/400 [==============================] - 91s 228ms/step - loss: 5.6385 - mean_absolute_error: 1.7225 - val_loss: 6.3991 - val_mean_absolute_error: 1.9165 Epoch 11/25 400/400 [==============================] - 91s 228ms/step - loss: 5.7589 - mean_absolute_error: 1.7666 - val_loss: 14.0191 - val_mean_absolute_error: 2.8988 Epoch 12/25 400/400 [==============================] - 92s 229ms/step - loss: 5.3819 - mean_absolute_error: 1.6724 - val_loss: 7.1035 - val_mean_absolute_error: 2.1311 Epoch 13/25 400/400 [==============================] - 91s 227ms/step - loss: 5.5961 - mean_absolute_error: 1.7425 - val_loss: 14.4304 - val_mean_absolute_error: 2.9596 Epoch 14/25 400/400 [==============================] - 91s 227ms/step - loss: 5.3910 - mean_absolute_error: 1.6667 - val_loss: 7.3332 - val_mean_absolute_error: 2.1058 Epoch 15/25 400/400 [==============================] - 91s 228ms/step - loss: 5.3278 - mean_absolute_error: 1.6476 - val_loss: 8.5243 - val_mean_absolute_error: 2.1570 Epoch 16/25 400/400 [==============================] - 91s 227ms/step - loss: 5.1909 - mean_absolute_error: 1.6277 - val_loss: 10.1045 - val_mean_absolute_error: 2.4271 Epoch 17/25 400/400 [==============================] - 91s 228ms/step - loss: 5.5173 - mean_absolute_error: 1.6810 - val_loss: 7.0249 - val_mean_absolute_error: 2.0507 Epoch 18/25 400/400 [==============================] - 91s 228ms/step - loss: 4.8198 - mean_absolute_error: 1.5651 - val_loss: 9.4390 - val_mean_absolute_error: 2.4027 Epoch 19/25 400/400 [==============================] - 91s 228ms/step - loss: 5.0561 - mean_absolute_error: 1.6042 - val_loss: 6.4782 - val_mean_absolute_error: 1.9549 Epoch 20/25 400/400 [==============================] - 91s 227ms/step - loss: 4.9979 - mean_absolute_error: 1.5990 - val_loss: 7.7401 - val_mean_absolute_error: 2.0900 Epoch 21/25 400/400 [==============================] - 91s 227ms/step - loss: 5.0527 - mean_absolute_error: 1.6058 - val_loss: 12.2271 - val_mean_absolute_error: 2.7062 Epoch 22/25 400/400 [==============================] - 91s 227ms/step - loss: 4.1005 - mean_absolute_error: 1.4261 - val_loss: 7.2351 - val_mean_absolute_error: 2.0184 Epoch 23/25 400/400 [==============================] - 91s 227ms/step - loss: 5.1156 - mean_absolute_error: 1.6122 - val_loss: 6.6283 - val_mean_absolute_error: 1.9421 Epoch 24/25 400/400 [==============================] - 91s 228ms/step - loss: 5.0533 - mean_absolute_error: 1.6155 - val_loss: 14.7405 - val_mean_absolute_error: 3.0259 Epoch 25/25 400/400 [==============================] - 91s 228ms/step - loss: 5.0501 - mean_absolute_error: 1.6213 - val_loss: 12.0591 - val_mean_absolute_error: 2.6012 --- 2297.5507295131683 seconds --- 1234567plt.plot(hist.history['loss'])plt.plot(hist.history['val_loss'])plt.title('Model MSE / Loss')plt.ylabel('MSE/Loss')plt.xlabel('Epoch')plt.legend(['Train', 'Test'], loc='upper left')plt.show() 1234567plt.plot(hist.history['mean_absolute_error'])plt.plot(hist.history['val_mean_absolute_error'])plt.title('Model Mean Absolute Error')plt.ylabel('MAE')plt.xlabel('Epoch')plt.legend(['Train', 'Test'], loc='upper left')plt.show() 1234567import gcdel train_gendel valid_gendel X_traindel y_traindel train_dfgc.collect() 6378 1model.save_weights('./trained_model.h5', overwrite=True) 12from os import listdir, makedirsfrom os.path import isfile, join, basename, splitext, isfile, exists Test data Normalize123456789101112131415def load_test(ts_length = 150000): base_dir = './test/' test_files = [f for f in listdir(base_dir) if isfile(join(base_dir, f))] ts = np.empty([len(test_files), ts_length]) ids = [] i = 0 for f in tqdm(test_files): ids.append(splitext(f)[0]) t_df = pd.read_csv(base_dir + f, dtype={&quot;acoustic_data&quot;: np.int8}) ts[i, :] = t_df['acoustic_data'].values i = i + 1 return ts, ids 1test_data, test_ids = load_test() 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2624/2624 [00:27&lt;00:00, 97.07it/s] 123X_test = test_dataX_test = np.expand_dims(X_test, 2)X_test.shape (2624, 150000, 1) 1y_pred = model.predict(X_test) 1submission_df = pd.DataFrame({'seg_id': test_ids, 'time_to_failure': y_pred[:, 0]}) 1submission_df.to_csv(&quot;submission.csv&quot;, index=False) í›„ê¸° ì‹œê³„ì—´ ë°ì´í„°ì…‹ì—ë‹¤ ë„ë€ìŠ¤í¬ë¨¸ í•´ë³´ë‹ˆ í• ë§Œ í•˜ì§€ë§Œ GPUê°€ ë²„í‹°ì§ˆ ëª»í•¨..","link":"/2020/12/06/kaggle-try/"},{"title":"ë”¥ëŸ¬ë‹-ì…ë¬¸í•˜ê¸°-9","text":"ì§€ë‚œë²ˆì— ì´ì–´ì„œ ì˜¤ë””ì˜¤ ë”¥ëŸ¬ë‹ 2ë²ˆì§¸2. Sound Representationìœ„ì—ì„œ Samplingëœ discreteí•œ ë°ì´í„°ë¥¼ ì´ì œ ìš°ë¦¬ëŠ” í‘œí˜„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì–´ë–¤ ìš”ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì €í¬ê°€ ë°ì´í„°ë¥¼ í‘œí˜„í•´ì•¼í• ê¹Œìš”?, ì²«ë²ˆì§¸ëŠ” ì‹œê°„ì˜ íë¦„ì— ë”°ë¼, ê³µê¸°ì˜ íŒŒë™ì˜ í¬ê¸°ë¡œ ë³´ëŠ” Time-domain Representation ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ë‘ë²ˆì§¸ëŠ” ì‹œê°„ì— ë”°ë¼ì„œ frequencyì˜ ë³€í™”ë¥¼ ë³´ëŠ” Time-Frequency representationì´ ìˆìŠµë‹ˆë‹¤. 2.1. Time domain - WaveformWaveformì˜ ê²½ìš°ì—ëŠ” ì˜¤ë””ì˜¤ì˜ ìì—°ì ì´ í‘œí˜„ì…ë‹ˆë‹¤. ì‹œê°„ì´ xì¶•ìœ¼ë¡œ ê·¸ë¦¬ê³  amplitudeê°€ yì¶•ìœ¼ë¡œ í‘œí˜„ì´ ë©ë‹ˆë‹¤. 1234import librosa.displayfig = plt.figure(figsize = (14,5))librosa.display.waveplot(y[0:10000], sr=sr) &lt;matplotlib.collections.PolyCollection at 0x7fa325708d50&gt; ì •í˜„íŒŒ (Sinusoid)ëª¨ë“  ì‹ í˜¸ëŠ” ì£¼íŒŒìˆ˜(frequency)ì™€ í¬ê¸°(magnitude), ìœ„ìƒ(phase)ì´ ë‹¤ë¥¸ ì •í˜„íŒŒ(sinusolida signal)ì˜ ì¡°í•©ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. í“¨ë¦¬ì— ë³€í™˜ì€ ì¡°í•©ëœ ì •í˜„íŒŒì˜ í•©(í•˜ëª¨ë‹ˆ) ì‹ í˜¸ì—ì„œ ê·¸ ì‹ í˜¸ë¥¼ êµ¬ì„±í•˜ëŠ” ì •í˜„íŒŒë“¤ì„ ê°ê° ë¶„ë¦¬í•´ë‚´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. 1234567sr = 16000 # sample rateT = 2.0 # secondst = np.linspace(0, T, int(T*sr), endpoint=False) # time variablex = 0.5*np.sin(2*np.pi*440*t) # pure sine wave at 440 Hz# y = 0.5*numpy.sin(2*numpy.pi*400*t)ipd.Audio(x, rate=sr) # load a NumPy array 1librosa.display.waveplot(x[:50], sr=sr) &lt;matplotlib.collections.PolyCollection at 0x7fa327a01550&gt; í‘¸ë¦¬ì— ë³€í™˜ (Fourier transform)í‘¸ë¦¬ì— ë³€í™˜(Fourier transform)ì„ ì§ê´€ì ìœ¼ë¡œ ì„¤ëª…í•˜ë©´ í‘¸ë¦¬ì— ë³€í™˜ì€ ì„ì˜ì˜ ì…ë ¥ ì‹ í˜¸ë¥¼ ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜ë¥¼ ê°–ëŠ” ì£¼ê¸°í•¨ìˆ˜(ë³µìˆ˜ ì§€ìˆ˜í•¨ìˆ˜)ë“¤ì˜ í•©ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ í‘œí˜„í•˜ëŠ” ê²ƒ ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ê° ì£¼ê¸°í•¨ìˆ˜ë“¤ì˜ ì§„í­ì„ êµ¬í•˜ëŠ” ê³¼ì •ì„ í“¨ë¦¬ì— ë³€í™˜ì´ë¼ê³  í•©ë‹ˆë‹¤. ì£¼ê¸°(period): íŒŒë™ì´ í•œë²ˆ ì§„ë™í•˜ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„, ë˜ëŠ” ê·¸ ê¸¸ì´, ì¼ë°˜ì ìœ¼ë¡œ siní•¨ìˆ˜ì˜ ì£¼ê¸°ëŠ” \\(2\\pi /w\\)ì…ë‹ˆë‹¤ ì£¼íŒŒìˆ˜(frequency): 1ì´ˆë™ì•ˆì˜ ì§„ë™íšŸìˆ˜ì…ë‹ˆë‹¤. í“¨ë¦¬ì— ë³€í™˜ì˜ ì‹ì„ ì‚´í´ë´…ì‹œë‹¤. $$y(t)=\\sum_{k=-\\infty}^\\infty A_k , \\exp \\left( i\\cdot 2\\pi\\frac{k}{T} t \\right)$$ ì´ ì‹ì„ í•˜ë‚˜ì‹ í•´ì„í•´ë´…ì‹œë‹¤.\\(k\\)ëŠ” \\(-\\infty\\) ~ \\(\\infty\\)ì˜ ë²”ìœ„ë¥¼ ê°€ì§€ê³  ì›€ì§ì…ë‹ˆë‹¤.ì´ê²ƒì€ ì£¼ê¸°í•¨ìˆ˜ë“¤ì˜ ê°¯ìˆ˜ì…ë‹ˆë‹¤. ì–´ë– í•œ ì‹ í˜¸ê°€ ë‹¤ë¥¸ ì£¼ê¸°í•¨ìˆ˜ë“¤ì˜ í•©ìœ¼ë¡œ í‘œí˜„ë˜ëŠ”ë°, ê·¸ ì£¼ê¸°í•¨ìˆ˜ëŠ” ë¬´í•œëŒ€ì˜ ë²”ìœ„ì— ìˆêµ°ìš”. ê·¸ë ‡ë‹¤ë©´ \\(A_k\\)ì€ ê·¸ ì‚¬ì¸í•¨ìˆ˜ì˜ ì§„í­ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ ì‹ì€ ì‹œê°„ì— ëŒ€í•œ ì…ë ¥ì‹ í˜¸ \\(y_{t}\\)ê°€ \\(\\exp \\left( i\\cdot 2\\pi\\frac{k}{T} t \\right)\\) ì™€ ì§„í­(\\(A_k\\))ì˜ ì„ í˜•ê²°í•©ìœ¼ë¡œ í‘œí˜„ë¨ì„ ë§í•˜ê³  ìˆêµ°ìš”. ìœ„ ê·¸ë¦¼ì„ ë³¸ë‹¤ë©´ ì¡°ê¸ˆ ë” ëª…í™•íˆ ì•Œìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë¶‰ì€ìƒ‰ ë¼ì¸ì´ ì…ë ¥ì‹ í˜¸ \\(y_{t}\\) ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ë‹¤ë£¨ê²Œ ë˜ëŠ” ë°ì´í„°ì¸ ìŒì•…ì´ë‚˜ ëª©ì†Œë¦¬ ê°™ì€ ë°ì´í„° ì—­ì‹œ complex toneì…ë‹ˆë‹¤. ì—¬ë ¤ê°œì˜ ì£¼íŒŒìˆ˜ì˜ì—­ì´ í•©ì³ì§„ ê²ƒì´ì£ . ì´ëŸ¬í•œ ì—¬ëŸ¬ê°œì˜ ì£¼íŒŒìˆ˜ ì˜ì—­ì„ ë¶„ë¦¬í•˜ì!ê°€ ì£¼ìš”í•œ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤. íŒŒë€ìƒ‰ ì£¼ê¸°í•¨ìˆ˜ë“¤ì„ ë³´ì‹ ë‹¤ë©´ ì—¬ëŸ¬ê°œì˜ ì£¼ê¸°í•¨ìˆ˜ë“¤ì„ ì°¾ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ ì£¼ê¸°í•¨ìˆ˜ë“¤ì€ ê³ ìœ ì˜ ì£¼íŒŒìˆ˜(frequency)ì™€ ê°•ë„(amplitude)ë¥¼ ê°€ì§€ê³  ìˆê³  ê·¸ê²ƒì´ íŒŒë€ìƒ‰ì˜ ë¼ì¸ë“¤ë¡œ í‘œí˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì§„í­ì— ëŒ€í•œ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.$$A_k = \\frac{1}{T} \\int_{-\\frac{T}{2}}^\\frac{T}{2} f(t) , \\exp \\left( -i\\cdot 2\\pi \\frac{k}{T} t \\right) , dt$$ì—¬ê¸°ì„œ í•˜ë‚˜ì˜ ì˜ë¬¸ì ì´ ë“œì‹¤ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì£¼ê¸°í•¨ìˆ˜ì˜ í•©ìœ¼ë¡œ í‘œí˜„ëœë‹¤ê³  í–ˆëŠ”ë° ì €í¬ê°€ ë³´ê³  ìˆëŠ”ê²ƒì€ \\(\\exp \\left( i\\cdot 2\\pi\\frac{k}{T} t \\right)\\) ì§€ìˆ˜í•¨ìˆ˜ì˜ í˜•íƒœì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì§€ìˆ˜í•¨ìˆ˜ì™€ ì£¼ê¸°í•¨ìˆ˜ ì‚¬ì´ì˜ ì—°ê´€ê´€ê³„ëŠ” ë¬´ì—‡ì¼ê¹Œìš”? ê·¸ ê´€ê³„ë¥¼ ì°¾ì€ ê²ƒì´ ë°”ë¡œ ì˜¤ì¼ëŸ¬ ê³µì‹ì…ë‹ˆë‹¤. $$e^{i\\theta} = \\cos{\\theta} + i\\sin{\\theta}$$ ì´ ì‹ì„ ìœ„ ì‹ì²˜ëŸ¼ í‘œí˜„í•œë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤$$\\exp \\left( i\\cdot 2\\pi\\frac{k}{T} t \\right) = \\cos\\left({2\\pi\\frac{k}{T}}\\right) + i\\sin\\left({2\\pi\\frac{k}{T}}\\right)$$ ì—¬ê¸°ì„œ \\(\\cos{2\\pi\\frac{k}{T}}\\), \\(i\\sin{2\\pi\\frac{k}{T}}\\) í•¨ìˆ˜ëŠ” ì£¼ê¸°ì™€ ì£¼íŒŒìˆ˜ë¥¼ ê°€ì§€ëŠ” ì£¼ê¸°í•¨ìˆ˜ì…ë‹ˆë‹¤. ì¦‰ í“¨ë¦¬ì— ë³€í™˜ì€ ì…ë ¥ singalì´ ì–´ë–¤ê²ƒì¸ì§€ ìƒê´€ì—†ì´ sin, cosê³¼ ê°™ì€ ì£¼ê¸°í•¨ìˆ˜ë“¤ì˜ í•©ìœ¼ë¡œ í•­ìƒ ë¶„í•´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. Fourier Transformì˜ Orthogonal$$y(t)=\\sum_{k=-\\infty}^\\infty A_k , \\exp \\left( i\\cdot 2\\pi\\frac{k}{T} t \\right)$$ ì–´ë– í•œ ì£¼ê¸°í•¨ìˆ˜ë¥¼ ìš°ë¦¬ëŠ” cosê³¼ siní•¨ìˆ˜ë¡œ í‘œí˜„í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ í•œê°€ì§€ ì¬ë°ŒëŠ” ì ì€, ì´ í•¨ìˆ˜ë“¤ì´ ì§êµí•˜ëŠ” í•¨ìˆ˜(orthogonal)ë¼ëŠ” ì ì´ë‹¤.$${ \\exp \\left(i\\cdot 2\\pi\\frac{k}{T} t\\right) } = orthogonal$$ ë²¡í„°ì˜ ì§êµëŠ” í•´ë‹¹ ë²¡í„°ë¥¼ í†µí•´ í‰ë©´ì˜ ëª¨ë“  ì¢Œí‘œë¥¼ í‘œí˜„í• ìˆ˜ ìˆì—ˆë‹¤. í•¨ìˆ˜ì˜ ë‚´ì ì€ ì ë¶„ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆëŠ”ë°, ë§Œì•½ êµ¬ê°„ [a,b]ì—ì„œ ì§êµí•˜ëŠ” í•¨ìˆ˜ëŠ” êµ¬ê°„ [a,b]ì˜ ëª¨ë“  í•¨ìˆ˜ë¥¼ í‘œí˜„í• ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ„ ì¼€ì´ìŠ¤ì—ì„œëŠ” cos, sin í•¨ìˆ˜ê°€ ì‚¬ì‹¤ìƒ ìš°ë¦¬ ì…ë ¥ì‹ í˜¸ì— ëŒ€í•´ì„œ ê¸°ì €ê°€ ë˜ì–´ì£¼ëŠ” í•¨ìˆ˜ë¼ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. DFT (Discrete Fourier Transform)í•œê°€ì§€ ì˜ë¬¸ì ì´ ë“­ë‹ˆë‹¤. ë°”ë¡œ, ìš°ë¦¬ê°€ samplingìœ¼ë¡œ ë“¤ì–´ì˜¨ ë°ì´í„°ëŠ” ë°”ë¡œ ì‹œê°„ì˜ ê°„ê²©ì— ë”°ë¥¸ ì†Œë¦¬ì˜ amplitudeì˜ discreteí•œ ë°ì´í„°ì´ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ë ‡ë‹¤ë©´ ìœ„ í‘¸ë¦¬ì— ë³€í™˜ ì‹ì„ Discreteí•œ ì˜ì—­ìœ¼ë¡œ ìƒê°í•´ë´…ì‹œë‹¤. ë§Œì•½ì— ìš°ë¦¬ê°€ ìˆ˜ì§‘í•œ ë°ì´í„° \\(y_{n}\\)ì—ì„œ, ì´ì‚° ì‹œê³„ì—´ ë°ì´í„°ê°€ ì£¼ê¸° \\(N\\)ìœ¼ë¡œ ë°˜ë³µí•œë‹¤ê³  í• ë•Œ, DFTëŠ” ì£¼íŒŒìˆ˜ì™€ ì§„í­ì´ ë‹¤ë¥¸ \\(N\\)ê°œì˜ ì‚¬ì¸ í•¨ìˆ˜ì˜ í•©ìœ¼ë¡œ í‘œí˜„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.$$y_n = \\frac{1}{N} \\sum_{k=0}^{N-1} Y_k \\cdot \\exp \\left( i\\cdot 2\\pi\\frac{k}{N} n \\right)$$ ìœ„ ì‹ì„ ë³´ë©´ kì˜ rangeê°€ 0ë¶€í„° \\(N-1\\)ë¡œ ë³€í™”í–ˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ë•Œ Spectrum \\(Y_{k}\\)ë¥¼ ì›ë˜ì˜ ì‹œê³„ì—´ ë°ì´í„°ì— ëŒ€í•œ í“¨ë¦¬ì— ë³€í™˜ê°’ì´ë¼ê³  í•˜ì£ . $$Y_k = \\sum_{n=0}^{N-1} y_n\\cdot \\exp \\left( -i\\cdot 2\\pi\\frac{k}{N} n \\right)$$ \\(y_{n}\\) : input signal \\(n\\) : Discrete time index \\(k\\) : discrete frequency index \\(Y_{k}\\) : kë²ˆì§¸ frequenyì— ëŒ€í•œ Spectrumì˜ ê°’ 123456789def DFT(x): N = len(x) X = np.array([]) nv = np.arange(N) for k in range(N): s = np.exp(1j*2*np.pi*k/N*nv) X = np.append(X, sum(x*np.conjugate(s))) return X STFT (Short-Time Fourier Transform)FFTëŠ” ì‹œê°„ì— íë¦„ì— ë”°ë¼ ì‹ í˜¸ì˜ ìˆ˜íŒŒìˆ˜ê°€ ë³€í–ˆì„ë•Œ, ì–´ëŠ ì‹œê°„ëŒ€ì— ì£¼íŒŒìˆ˜ê°€ ë³€í•˜ëŠ”ì§€ ëª¨ë¥´ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ì„œ, STFTëŠ” ì‹œê°„ì˜ ê¸¸ì´ë¥¼ ë‚˜ëˆ ì„œ ì´ì œ í“¨ë¦¬ì— ë³€í™˜ì„ í•˜ê²Œ ë©ë‹ˆë‹¤. ì¦‰ FFTë¥¼ í–ˆì„ë•ŒëŠ” Time dominaì— ëŒ€í•œ ì •ë³´ê°€ ë‚ ì•„ê°€ê²Œ ë˜ëŠ” ê²ƒì´ì£ . ì£¼íŒŒìˆ˜ì˜ íŠ¹ì„±ì´ ì‹œê°„ì— ë”°ë¼ ë‹¬ë¼ì§€ëŠ” ì‚¬ìš´ë“œë¥¼ ë¶„ì„í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” signal ë°ì´í„°ì— ì í•©í•˜ë‹¤. ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì¼ì •í•œ ì‹œê°„ êµ¬ê°„ (window size)ë¡œ ë‚˜ëˆ„ê³ , ê° êµ¬ê°„ì— ëŒ€í•´ì„œ ìŠ¤í™íŠ¸ëŸ¼ì„ êµ¬í•˜ëŠ” ë°ì´í„°ì´ë‹¤. ì´ëŠ” Time-frequency 2ì°¨ì› ë°ì´í„°ë¡œ í‘œí˜„ì´ ë©ë‹ˆë‹¤. $$X(l,k) = \\sum_{n=0}^{N-1} w(n) x(n+lH)\\exp^{\\frac{-2\\pi k n}{N}}$$ \\(N\\) : FFT size Windowë¥¼ ì–¼ë§ˆë‚˜ ë§ì€ ì£¼íŒŒìˆ˜ ë°´ë“œë¡œ ë‚˜ëˆ„ëŠ”ê°€ ì…ë‹ˆë‹¤. Duration ìƒ˜í”Œë§ ë ˆì´íŠ¸ë¥¼ windowë¡œ ë‚˜ëˆˆ ê°’ì…ë‹ˆë‹¤. $$T= window/SR$$ T(Window) = 5T(Signal), durationì€ ì‹ í˜¸ì£¼ê¸°ë³´ë‹¤ 5ë°° ì´ìƒ ê¸¸ê²Œ ì¡ì•„ì•¼í•œë‹¤. 440Hz ì‹ í˜¸ì˜ window sizeëŠ” 5*(1/440)ì´ ë©ë‹ˆë‹¤. \\(w(n)\\) : Window function ì¼ë°˜ì ìœ¼ë¡œ Hann windowê°€ ì“°ì…ë‹ˆë‹¤. \\(n\\) : Window size Window í•¨ìˆ˜ì— ë“¤ì–´ê°€ëŠ” Sampleì˜ ì–‘ì…ë‹ˆë‹¤. ì‘ì„ìˆ˜ë¡ Low-frequency resolutionì„ ê°€ì§€ê²Œ ë˜ê³ , high-time resolutionì„ ê°€ì§‘ë‹ˆë‹¤. ê¸¸ìˆ˜ë¡ High-frequency, low time resolutionì„ ê°€ì§‘ë‹ˆë‹¤. \\(H\\) : Hop size ìœˆë„ìš°ê°€ ê²¹ì¹˜ëŠ” ì‚¬ì´ì¦ˆì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” 1/4ì •ë„ë¥¼ ê²¹ì¹˜ê²Œ í•©ë‹ˆë‹¤. STFTì˜ ê²°ê³¼ëŠ” ì¦‰ ì‹œê°„ì˜ íë¦„(Window)ì— ë”°ë¥¸ Frequencyì˜ì—­ë³„ Amplitudeë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. 1234567sr = 16000 # sample rateT = 2.0 # secondst = np.linspace(0, T, int(T * sr), endpoint=False) # time variablex = 0.5 * np.sin(2 * np.pi * 440 * t) # pure sine wave at 440 Hz# y = 0.5*numpy.sin(2*numpy.pi*400*t)ipd.Audio(x, rate=sr) # load a NumPy array 12345678910111213141516print(len(y))D = librosa.stft(y)print(D.shape, D)# phase ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‚ ë¦°ë‹¤.D_mag = np.abs(D)print(D_mag)print(D_mag.shape)magnitude, phase = librosa.magphase(D)print(magnitude)print(magnitude.shape)print(magnitude-D_mag) 48944 (1025, 96) [[-2.1494275e-01+0.0000000e+00j -2.0992082e-01+0.0000000e+00j -2.0418610e-01+0.0000000e+00j ... -1.9438802e-01+0.0000000e+00j -1.9518623e-01+0.0000000e+00j -2.3163199e-01+0.0000000e+00j] [ 9.3493842e-02+6.7762636e-21j 1.2481287e-01+4.8880498e-03j 7.3961377e-02+1.3274251e-03j ... 7.7925511e-02-1.7781712e-02j 9.6285135e-02+1.7115690e-02j 1.1564651e-01-5.2810002e-02j] [ 1.9829417e-02+8.2818238e-19j -3.1706840e-02+1.5587136e-02j 5.7078212e-02-2.0519590e-02j ... 2.3265863e-02+7.6752454e-02j 3.0044108e-03-6.0352467e-02j 5.4616658e-03+6.8522707e-02j] ... [-5.3125373e-03-1.2618632e-18j 3.4157380e-03-1.7295172e-03j -1.8859134e-03-3.5993013e-04j ... -7.6227036e-04-9.3025468e-05j -1.8814437e-04-8.4138475e-05j 4.7763987e-04-5.3400453e-04j] [ 2.1248308e-03+1.5585406e-19j -1.4035926e-03+8.0862024e-05j 2.4144542e-03+3.4830419e-04j ... -2.3595782e-04+1.1687888e-03j 1.1331354e-04+1.2911476e-04j 2.8909228e-04+3.3650018e-04j] [-8.1756472e-04+0.0000000e+00j -9.3529455e-04+0.0000000e+00j -1.4104146e-03+0.0000000e+00j ... 1.3452002e-03+0.0000000e+00j -9.2299597e-06+0.0000000e+00j -4.9439305e-04+0.0000000e+00j]] [[2.1494275e-01 2.0992082e-01 2.0418610e-01 ... 1.9438802e-01 1.9518623e-01 2.3163199e-01] [9.3493842e-02 1.2490856e-01 7.3973291e-02 ... 7.9928555e-02 9.7794548e-02 1.2713383e-01] [1.9829417e-02 3.5331041e-02 6.0654562e-02 ... 8.0201246e-02 6.0427204e-02 6.8740025e-02] ... [5.3125373e-03 3.8286415e-03 1.9199529e-03 ... 7.6792570e-04 2.0610093e-04 7.1645004e-04] [2.1248308e-03 1.4059199e-03 2.4394479e-03 ... 1.1923688e-03 1.7178644e-04 4.4362905e-04] [8.1756472e-04 9.3529455e-04 1.4104146e-03 ... 1.3452002e-03 9.2299597e-06 4.9439305e-04]] (1025, 96) [[2.1494275e-01 2.0992082e-01 2.0418610e-01 ... 1.9438802e-01 1.9518623e-01 2.3163199e-01] [9.3493842e-02 1.2490856e-01 7.3973291e-02 ... 7.9928555e-02 9.7794548e-02 1.2713383e-01] [1.9829417e-02 3.5331041e-02 6.0654562e-02 ... 8.0201246e-02 6.0427204e-02 6.8740025e-02] ... [5.3125373e-03 3.8286415e-03 1.9199529e-03 ... 7.6792570e-04 2.0610093e-04 7.1645004e-04] [2.1248308e-03 1.4059199e-03 2.4394479e-03 ... 1.1923688e-03 1.7178644e-04 4.4362905e-04] [8.1756472e-04 9.3529455e-04 1.4104146e-03 ... 1.3452002e-03 9.2299597e-06 4.9439305e-04]] (1025, 96) [[0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] ... [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.] [0. 0. 0. ... 0. 0. 0.]] 123456S = librosa.core.stft(audio_np, n_fft=1024, hop_length=512, win_length=1024)D = np.abs(S)**2log_S = librosa.power_to_db(S, ref=np.max) #ì†Œë¦¬ì˜ ë‹¨ìœ„ë¥¼ dbë¡œ ë°”ê¿ˆ plt.figure(figsize=(12,4))librosa.display.specshow(log_S, sr=16000, x_axis='time') Window function?ìœ„ì—ì„œ Window functionê³¼ Window sizeë¼ëŠ” ì´ì•¼ê¸°ê°€ ë‚˜ì˜¤ê³  ìˆìŠµë‹ˆë‹¤. ìœˆë„ìš° Functionê³¼ SizeëŠ” ì™œ ì“°ëŠ” ê²ƒì´ë©° ì–´ë–¨ë•Œ ì“°ëŠ” ê²ƒì¼ê¹Œìš”? Window functionì˜ ì£¼ëœ ê¸°ëŠ¥ì€ main-lobeì˜ widthì™€ side-lobeì˜ ë ˆë²¨ì˜ Trade-off ë¥¼ ì œì–´í•´ ì¤€ë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ê¹ìŠ¤ í˜„ìƒì„ ë§‰ì•„ì£¼ëŠ” ê³ ë§ˆìš´ ì¹œêµ¬ì´ê¸°ë„ í•˜ì£ . ì§€ê¸ˆë‚˜ì˜¨ main-lobe, side-bloe, ê¹ìŠ¤í˜„ìƒì€ ë¬´ì—‡ì¼ê¹Œìš”? 123456789101112def frame_audio(audio, FFT_size=1024, hop_size=20, sample_rate = 22050): audio = np.pad(audio, int(FFT_size/2), mode='reflect') frame_len = np.round(sample_rate*hop_size / 1000).astype(int) frame_num = int((len(audio) - FFT_size) / frame_len) + 1 frames = np.zeros((frame_num, FFT_size)) for n in range(frame_num): frames[n] = audio[n*frame_len:n*frame_len+FFT_size] return framesaudio_framed = frame_audio(audio_np)print(&quot;Framed audio shape: {}&quot;.format(audio_framed.shape)) Framed audio shape: (469, 1024) 123456789101112131415161718from scipy import signalwindow = signal.get_window(&quot;hann&quot;, 1024, fftbins=True)audio_win = audio_framed * windowind = 2plt.figure(figsize=(15,6))plt.subplot(3,1,1)plt.plot(window)plt.grid(True)plt.subplot(3,1,2)plt.plot(audio_framed[ind])plt.grid(True)plt.subplot(3,1,3)plt.plot(audio_win[ind])plt.grid(True)plt.show() í”Œë¡¯ì„ ë³´ê²Œ ëœë‹¤ë©´ windowingì„ ì ìš©í•˜ê¸°ì „ plotì€ ëë¶€ë¶„ì´ ë‹¤ ë‹¤ë¥´ì§€ë§Œ, windowingì„ ì§€ë‚˜ê³  ë‚˜ì„œ ë‚˜ì˜¤ëŠ” plotì€ ëì´ 0 ìœ¼ë¡œ ì¼ì¹˜í•œë‹¤ëŠ” íŠ¹ì„±ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. Window size?ìœˆë„ìš° ì‚¬ì´ì¦ˆëŠ” ì¼ë°˜ì ìœ¼ë¡œ timeê³¼ frequencyì˜ resolutionsì„ ì œì–´í•´ ì¤ë‹ˆë‹¤. short-window : ë‚®ì€ frequency resolution, ë†’ì€ time-resolutionì„ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤. Long-window : ë†’ì€ frequency resolutionì„ ê°€ì§€ë©°, ë‚®ì€ time-resolutionì„ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤. SpectrogramSpectrogramì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ ê³ ë¯¼í•´ë´…ì‹œë‹¤.ì¼ë°˜ì ìœ¼ë¡œ í”„ë¡œì„¸ìŠ¤ëŠ” ì…ë ¥ì‹ í˜¸ì— ëŒ€í•´ì„œ window functionì„ í†µê³¼í•˜ì—¬ window sizeë§Œí¼ sampling ëœ dataë¥¼ ë°›ì•„ì„œ Discrete Fourier Transformì„ ê±°ì¹˜ê²Œ ë©ë‹ˆë‹¤. DFTë¥¼ ê±°ì¹œ ì‹ í˜¸ë“¤ì€ Frequencyì™€ Amplitudeì˜ ì˜ì—­ì„ ê°€ì§€ëŠ” Spectrumì´ ë©ë‹ˆë‹¤. ì´í›„ ì´ë¥¼ 90ë„ë¡œ íšŒì „ì‹œì¼œì„œ, time domainìœ¼ë¡œ stackí•˜ê²Œ ë©ë‹ˆë‹¤. Spectrogramì€ Frequency Scaleì— ëŒ€í•´ì„œ Scalingì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. ì£¼íŒŒìˆ˜ ì˜ì—­ì— Scalingì„ í•˜ëŠ” ì´ìœ ëŠ”, ì¸ê°„ì˜ ì£¼íŒŒìˆ˜ë¥¼ ì¸ì‹í•˜ëŠ” ë°©ì‹ê³¼ ì—°ê´€ì´ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ëŒì€, ì¸ì ‘í•œ ì£¼íŒŒìˆ˜ë¥¼ í¬ê²Œ êµ¬ë³„í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ìš°ë¦¬ì˜ ì¸ì§€ê¸°ê´€ì´ categoricalí•œ êµ¬ë¶„ì„ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë•Œë¬¸ì— ìš°ë¦¬ëŠ” ì£¼íŒŒìˆ˜ë“¤ì˜ Binì˜ ê·¸ë£¹ì„ ë§Œë“¤ê³  ì´ë“¤ì„ í•©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ, ì£¼íŒŒìˆ˜ ì˜ì—­ì—ì„œ ì–¼ë§ˆë§Œí¼ì˜ ì—ë„ˆì§€ê°€ ìˆëŠ”ì§€ë¥¼ ì°¾ì•„ë³¼ ê²ƒì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œëŠ” ì¸ê°„ì´ ì ì€ ì£¼íŒŒìˆ˜ì— ë” í’ë¶€í•œ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ê¸°ë•Œë¬¸ì—, ì£¼íŒŒìˆ˜ê°€ ì˜¬ë¼ê°ˆìˆ˜ë¡ í•„í„°ì˜ í­ì´ ë†’ì•„ì§€ë©´ì„œ ê³ ì£¼íŒŒëŠ” ê±°ì˜ ê³ ë ¤ë¥¼ ì•ˆí•˜ê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì•„ë˜ frequency scaleì€ ì–´ë–¤ ë°©ì‹ì„ í†µí•´ ì €ì£¼íŒŒìˆ˜ëŒ€ ì˜ì—­ì„ ê³ ë ¤í•  ê²ƒì´ê°€ì— ëŒ€í•œ ê³ ë¯¼ì´ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. Linear frequency scaleì¼ë°˜ì ìœ¼ë¡œ single tone(ìˆœìŒ)ë“¤ì˜ ë°°ìŒ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë¶„í¬ê°€ ì €ì£¼íŒŒìˆ˜ ì˜ì—­ì— ê¸°ìš¸ì–´ì ¸(skewed) ìˆìŠµë‹ˆë‹¤. Mel Scaleë©œ ìŠ¤í™íŠ¸ëŸ¼ì€ ì£¼íŒŒìˆ˜ ë‹¨ìœ„ë¥¼ ë‹¤ìŒ ê³µì‹ì— ë”°ë¼ ë©œ ë‹¨ìœ„ë¡œ ë°”ê¾¼ ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. $$m = 2595 \\log_{10}\\left(1 + \\frac{f}{700}\\right)$$ì¼ë°˜ì ìœ¼ë¡œëŠ” mel-scaled binì„ FFT sizeë³´ë‹¤ ì¡°ê¸ˆë” ì‘ê²Œ ë§Œë“œëŠ”ê²Œ ì¼ë°˜ì ì…ë‹ˆë‹¤. 1234# STFTS = librosa.core.stft(audio_np, n_fft=1024, hop_length=512, win_length=1024)# phase ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‚ ë¦°ë‹¤.D = np.abs(S)**2 1234# mel spectrogram (512 --&gt; 40)mel_basis = librosa.filters.mel(sr, 1024, n_mels=40)mel_S = np.dot(mel_basis, D)mel_S.shape (40, 404) 123456789import librosa.displayS = librosa.feature.melspectrogram(audio_np, sr=sr, n_mels = 128)log_S = librosa.power_to_db(S, ref=np.max)plt.figure(figsize=(12,4))librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')plt.title('Mel power sepctrogram')plt.colorbar(format='%+02.0f dB')plt.tight_layout() 123456789import librosa.displayS = librosa.feature.melspectrogram(audio_np, sr=sr, n_mels = 256)log_S = librosa.power_to_db(S, ref=np.max)plt.figure(figsize=(12,4))librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')plt.title('Mel power sepctrogram')plt.colorbar(format='%+02.0f dB')plt.tight_layout() Bark scaleê·€ê°€ ì¸ì‹í•˜ëŠ” ì£¼íŒŒìˆ˜ì˜ ì˜ì—­ì€ ëŒ€ëµ 20Hz~2000Hz ë¡œ ê°€ì •í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì£¼íŒŒìˆ˜ì— ëŒ€í•œ ì‚¬ëŒì˜ ì¸ì‹ì€ ë¹„ì„ í˜•ì ì…ë‹ˆë‹¤. ê·€ì™€ ë‡Œì˜ ê°€ì²­ëŒ€ì—­ì„ 24ê°œì˜ ëŒ€ì—­ìœ¼ë¡œ ë‚˜ëˆˆê²ƒì„ Barkë¼ê³  í•©ë‹ˆë‹¤! Bark scaleì€ 500Hzì´í•˜ì—ì„œëŠ” 100Hzì˜ ëŒ€ì—­í­ì„ ê°€ì§€ë©°, 500Hz ì´ìƒì—ì„œëŠ” ê° ëŒ€ì—­ì˜ ì¤‘ì‹¬ìˆ˜íŒŒìˆ˜ì˜ ëŒ€ëµ 20%ì— í•´ë‹¹í•˜ëŠ” ëŒ€ì—­í­ì„ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤. 20, 100, 200, 300, 400, 510, 630, 770, 920, 1080, 1270, 1480, 1720, 2000, 2320, 2700, 3150, 3700, 4400, 5300, 6400, 7700, 9500, 12000, 15500 ( Hz ) Log compression\\(10 * log10(\\frac{S}{ref})\\)ì˜ ë‹¨ìœ„ë¡œ ì‹ í˜¸ë¥¼ ìŠ¤ì¼€ì¼ë§ í•©ë‹ˆë‹¤. ì´ëŠ” spectrogramì„ ë°ì‹œë²¨ ìœ ë‹›ìœ¼ë¡œ ì „í™˜í•´ ì¤ë‹ˆë‹¤. 123#log compressionlog_mel_S = librosa.power_to_db(mel_S)log_mel_S.shape (40, 404) Discrete cosine transform (DCT)DCTëŠ” nê°œì˜ ë°ì´í„°ë¥¼ nê°œì˜ ì½”ì‚¬ì¸ í•¨ìˆ˜ì˜ í•©ìœ¼ë¡œ í‘œí˜„í•˜ì—¬ ë°ì´í„°ì˜ ì–‘ì„ ì¤„ì´ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì € ì£¼íŒŒìˆ˜ì— ì—ë„ˆì§€ê°€ ì§‘ì¤‘ë˜ê³  ê³  ì£¼íŒŒìˆ˜ ì˜ì—­ì— ì—ë„ˆì§€ê°€ ê°ì†Œí•©ë‹ˆë‹¤. Filter BankëŠ” ëª¨ë‘ Overlapping ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— Filter Bank ì—ë„ˆì§€ë“¤ ì‚¬ì´ì— ìƒê´€ê´€ê³„ê°€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì´ë‹¤. DCTëŠ” ì—ë„ˆì§€ë“¤ ì‚¬ì´ì— ì´ëŸ¬í•œ ìƒê´€ê´€ê³„ë¥¼ ë¶„ë¦¬ í•´ì£¼ëŠ” ì—­í™œì„ í•´ì¤ë‹ˆë‹¤. í•˜ì§€ë§Œ ì—¬ê¸°ì„œ 26ê°œ DCT Coefficient ë“¤ ì¤‘ 12ë§Œ ë‚¨ê²¨ì•¼ í•˜ëŠ”ë°, ê·¸ ì´ìœ ëŠ” DCT Coefficient ê°€ ë§ìœ¼ë©´, Filter Bank ì—ë„ˆì§€ì˜ ë¹ ë¥¸ ë³€í™”ë¥¼ ë‚˜íƒ€ë‚´ê²Œ ë˜ê³ , ì´ê²ƒì€ ìŒì„±ì¸ì‹ì˜ ì„±ëŠ¥ì„ ë‚®ì¶”ê²Œ ë©ë‹ˆë‹¤. 12345# mfcc (DCT)mfcc = librosa.feature.mfcc(S=log_mel_S, n_mfcc=13)mfcc = mfcc.astype(np.float32) # to save the memory (64 to 32 bits)plt.figure(figsize=(12,4))librosa.display.specshow(mfcc) &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f3a8975cc88&gt; 1234567891011mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)delta2_mfcc = librosa.feature.delta(mfcc, order=2)print(delta2_mfcc.shape)plt.figure(figsize=(12,4))librosa.display.specshow(delta2_mfcc)plt.ylabel('MFCC coeffs')plt.xlabel('Time')plt.title('MFCC')plt.colorbar()plt.tight_layout() (13, 148) 12345678def change_pitch(data, sr): y_pitch = data.copy() bins_per_octave = 12 pitch_pm = 2 pitch_change = pitch_pm * 2 * (np.random.uniform()) y_pitch = librosa.effects.pitch_shift(y_pitch.astype('float64'), sr, n_steps=pitch_change, bins_per_octave=bins_per_octave) return y_pitch 123456def waveform_aug(waveform,sr): y = change_pitch(waveform, sr) fig = plt.figure(figsize = (14,5)) librosa.display.waveplot(y, sr=sr) ipd.display(ipd.Audio(data=y, rate=sr)) return y, sr 12ipd.display(ipd.Audio(data=audio_np, rate=sr))y, sr = waveform_aug(audio_np, 16000) 1234567S = librosa.feature.melspectrogram(audio_np, sr=sr, n_mels = 128)log_S = librosa.power_to_db(S, ref=np.max)plt.figure(figsize=(12,4))librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')plt.title('Mel power sepctrogram')plt.colorbar(format='%+02.0f dB')plt.tight_layout() 1np.random.uniform(low=1.5, high=3) 2.6892527992385458 12345def value_aug(data): y_aug = data.copy() dyn_change = np.random.uniform(low=1.5, high=3) y_aug = y_aug * dyn_change return y_aug 1234def add_noise(data): noise = np.random.randn(len(data)) data_noise = data + 0.005 * noise return data_noise 123def hpss(data): y_harmonic, y_percussive = librosa.effects.hpss(data.astype('float64')) return y_harmonic, y_percussive 12def shift(data): return np.roll(data, 1600) 123456789def stretch(data, rate=1): input_length = len(data) streching = librosa.effects.time_stretch(data, rate) if len(streching) &gt; input_length: streching = streching[:input_length] else: streching = np.pad(streching, (0, max(0, input_length - len(streching))), &quot;constant&quot;) return streching 12345678910def change_pitch_and_speed(data): y_pitch_speed = data.copy() # you can change low and high here length_change = np.random.uniform(low=0.8, high=1) speed_fac = 1.0 / length_change tmp = np.interp(np.arange(0, len(y_pitch_speed), speed_fac), np.arange(0, len(y_pitch_speed)), y_pitch_speed) minlen = min(y_pitch_speed.shape[0], tmp.shape[0]) y_pitch_speed *= 0 y_pitch_speed[0:minlen] = tmp[0:minlen] return y_pitch_speed 1234567data_noise = add_noise(audio_np)data_roll = shift(audio_np)data_stretch = stretch(audio_np)pitch_speed = change_pitch_and_speed(audio_np)value = value_aug(audio_np)y_harmonic, y_percussive = hpss(audio_np)y_shift = shift(audio_np) 1ipd.Audio(data_noise, rate=fs) 12345678import matplotlib.pyplot as pltlibrosa.display.specshow(librosa.amplitude_to_db(magnitude, ref=np.max), y_axis='log', x_axis='time')plt.title('Power spectrogram')plt.colorbar(format='%+2.0f dB')plt.tight_layout()plt.show() 1234567891011mel_s = librosa.feature.melspectrogram(y=y, sr=sr)print(mel_s.shape)import matplotlib.pyplot as pltlibrosa.display.specshow(librosa.amplitude_to_db(mel_s, ref=np.max), y_axis='log', x_axis='time')plt.title('Power spectrogram')plt.colorbar(format='%+2.0f dB')plt.tight_layout()plt.show() (128, 96) 1234567891011mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)print(mfccs.shape)import matplotlib.pyplot as pltplt.figure(figsize=(10, 4))librosa.display.specshow(mfccs, x_axis='time')plt.colorbar()plt.title('MFCC')plt.tight_layout()plt.show() (40, 96) 12345678import matplotlib.pyplot as pltlibrosa.display.specshow(librosa.amplitude_to_db(mfccs, ref=np.max), y_axis='log', x_axis='time')plt.title('Power spectrogram')plt.colorbar(format='%+2.0f dB')plt.tight_layout()plt.show() ë“¤ë¦¬ëŠ” ì†Œë¦¬ = ë°°ê²½ì¡ìŒ + ëª©ì†Œë¦¬12filename_wav = &quot;./wav/voice.wav&quot;filename_noise = &quot;./wav/cafe_noise.wav&quot; 12import IPython.display as ipdipd.Audio(filename_wav) 12import IPython.display as ipdipd.Audio(filename_noise) 123456789101112data_wav, sr_wav = librosa.load(filename_wav, mono=True, sr=16000)data_noise, sr_noise = librosa.load(filename_noise, mono=True, sr=16000)print(data_wav.shape)print(data_noise.shape)# ì „ì²´ì ìœ¼ë¡œ ë“¤ë¦¬ëŠ” ì†Œë¦¬ëŠ” ì†Œë¦¬ì˜ í•©( ë°°ê²½ìŒ + ëª©ì†Œë¦¬ )data_wav_noise = data_wav[:] + data_noise[:len(data_wav)]pos=10print(&quot;wav: {:.8f}, noise {:.8f}, wav+noise: {:.8f}&quot;.format(data_wav[pos], data_noise[pos], data_wav_noise[pos])) (48944,) (1044712,) wav: -0.00009155, noise -0.00003052, wav + noise: -0.00012207 1ipd.Audio(data_wav_noise, rate=16000)","link":"/2020/12/03/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%ED%95%98%EA%B8%B0-9/"}],"tags":[{"name":"Dacon","slug":"Dacon","link":"/tags/Dacon/"},{"name":"Try","slug":"Try","link":"/tags/Try/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"DL","slug":"DL","link":"/tags/DL/"},{"name":"GAN","slug":"GAN","link":"/tags/GAN/"},{"name":"HEXO","slug":"HEXO","link":"/tags/HEXO/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"Tensorflow2","slug":"Tensorflow2","link":"/tags/Tensorflow2/"},{"name":"TF2","slug":"TF2","link":"/tags/TF2/"},{"name":"R","slug":"R","link":"/tags/R/"},{"name":"coding","slug":"coding","link":"/tags/coding/"},{"name":"Music EDA","slug":"Music-EDA","link":"/tags/Music-EDA/"},{"name":"Script","slug":"Script","link":"/tags/Script/"},{"name":"Linear Algebra","slug":"Linear-Algebra","link":"/tags/Linear-Algebra/"},{"name":"Audio","slug":"Audio","link":"/tags/Audio/"},{"name":"competition","slug":"competition","link":"/tags/competition/"},{"name":"Paper","slug":"Paper","link":"/tags/Paper/"},{"name":"Kaggle","slug":"Kaggle","link":"/tags/Kaggle/"}],"categories":[{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"GitPage","slug":"GitPage","link":"/categories/GitPage/"},{"name":"Kaggle, Dacon","slug":"Machine-Learning/Kaggle-Dacon","link":"/categories/Machine-Learning/Kaggle-Dacon/"},{"name":"Code","slug":"Code","link":"/categories/Code/"},{"name":"ilsang","slug":"ilsang","link":"/categories/ilsang/"},{"name":"Hexo","slug":"GitPage/Hexo","link":"/categories/GitPage/Hexo/"},{"name":"R","slug":"Code/R","link":"/categories/Code/R/"},{"name":"Competition","slug":"Machine-Learning/Competition","link":"/categories/Machine-Learning/Competition/"},{"name":"Papers","slug":"Machine-Learning/Papers","link":"/categories/Machine-Learning/Papers/"}]}